{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "from utils.PathologyDataset import PathologyDataset\n",
    "from utils.TissueExtractor import TissueExtractor\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Check tissue extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_extraction_strategies(test_img, test_mask):\n",
    "    extractor = TissueExtractor(patch_size=224, min_annotation_pixels=1)\n",
    "\n",
    "    # Test random strategy\n",
    "    print(\"\\n--- Testing RANDOM strategy ---\")\n",
    "    images_random, _ = extractor.get_valid_patches(\n",
    "        test_img, test_mask, num_patches=16, strategy=\"random\", min_distance=32\n",
    "    )\n",
    "    print(f\"Random: Extracted {len(images_random)} patches\")\n",
    "\n",
    "    # Test grid strategy\n",
    "    print(\"\\n--- Testing GRID strategy ---\")\n",
    "    images_grid, _ = extractor.get_valid_patches(\n",
    "        test_img,\n",
    "        test_mask,\n",
    "        num_patches=16,\n",
    "        strategy=\"grid\",\n",
    "    )\n",
    "    print(f\"Grid: Extracted {len(images_grid)} patches\")\n",
    "\n",
    "    # plot extracted patches\n",
    "    n_cols = max(len(images_random), len(images_grid), 1)\n",
    "    fig, axes = plt.subplots(2, n_cols, figsize=(n_cols * 2, 4), squeeze=False)\n",
    "\n",
    "    # Plot Random patches\n",
    "    for i in range(n_cols):\n",
    "        if i < len(images_random):\n",
    "            axes[0, i].imshow(images_random[i])\n",
    "        axes[0, i].axis(\"off\")\n",
    "    axes[0, 0].set_title(\"RANDOM strategy extracted patches\", loc=\"left\")\n",
    "\n",
    "    # Plot Grid patches\n",
    "    for i in range(n_cols):\n",
    "        if i < len(images_grid):\n",
    "            axes[1, i].imshow(images_grid[i])\n",
    "        axes[1, i].axis(\"off\")\n",
    "    axes[1, 0].set_title(\"GRID strategy extracted patches\", loc=\"left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Check Triple negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.array(PIL.Image.open(\"data/train_data/img_0000.png\").convert(\"RGB\"))\n",
    "test_mask = np.array(PIL.Image.open(\"data/train_data/mask_0000.png\").convert(\"L\"))\n",
    "visualize_extraction_strategies(test_img, test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.array(PIL.Image.open(\"data/train_data/img_0033.png\").convert(\"RGB\"))\n",
    "test_mask = np.array(PIL.Image.open(\"data/train_data/mask_0033.png\").convert(\"L\"))\n",
    "visualize_extraction_strategies(test_img, test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Luminal A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.array(PIL.Image.open(\"data/train_data/img_0006.png\").convert(\"RGB\"))\n",
    "test_mask = np.array(PIL.Image.open(\"data/train_data/mask_0006.png\").convert(\"L\"))\n",
    "visualize_extraction_strategies(test_img, test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.array(PIL.Image.open(\"data/train_data/img_0011.png\").convert(\"RGB\"))\n",
    "test_mask = np.array(PIL.Image.open(\"data/train_data/mask_0011.png\").convert(\"L\"))\n",
    "visualize_extraction_strategies(test_img, test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Luminal B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.array(PIL.Image.open(\"data/train_data/img_0021.png\").convert(\"RGB\"))\n",
    "test_mask = np.array(PIL.Image.open(\"data/train_data/mask_0021.png\").convert(\"L\"))\n",
    "visualize_extraction_strategies(test_img, test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.array(PIL.Image.open(\"data/train_data/img_0023.png\").convert(\"RGB\"))\n",
    "test_mask = np.array(PIL.Image.open(\"data/train_data/mask_0023.png\").convert(\"L\"))\n",
    "visualize_extraction_strategies(test_img, test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### HER2(+)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.array(PIL.Image.open(\"data/train_data/img_0029.png\").convert(\"RGB\"))\n",
    "test_mask = np.array(PIL.Image.open(\"data/train_data/mask_0029.png\").convert(\"L\"))\n",
    "visualize_extraction_strategies(test_img, test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.array(PIL.Image.open(\"data/train_data/img_0030.png\").convert(\"RGB\"))\n",
    "test_mask = np.array(PIL.Image.open(\"data/train_data/mask_0030.png\").convert(\"L\"))\n",
    "visualize_extraction_strategies(test_img, test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Check Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "\n",
    "TRAIN_DATA_DIR = \"./data/train_data\"\n",
    "TEST_DATA_DIR = \"./data/test_data\"\n",
    "TRAIN_LABELS_PATH = \"./data/train_labels.csv\"\n",
    "# Load training labels\n",
    "train_df = pd.read_csv(TRAIN_LABELS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Test1: Without patches (whole images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Without patches (whole images)\n",
    "print(\"=\" * 50)\n",
    "print(\"Test 1: Whole Images (no patches)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define simple transforms for testing\n",
    "test1_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_test1 = PathologyDataset(\n",
    "    data_dir=TRAIN_DATA_DIR,\n",
    "    labels_df=train_df,\n",
    "    transform=test1_transform,\n",
    "    use_mask=True,\n",
    "    use_patches=False,\n",
    "    use_stain_norm=False,\n",
    "    is_test=False,\n",
    ")\n",
    "\n",
    "# Gather first 4 images\n",
    "num_samples = 4\n",
    "imgs = []\n",
    "labels = []\n",
    "sample_ids = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Get sample\n",
    "    img_tensor, label_tensor = dataset_test1[i]\n",
    "\n",
    "    # Store data\n",
    "    imgs.append(img_tensor)\n",
    "    labels.append(label_tensor)\n",
    "    sample_ids.append(dataset_test1.samples[i])\n",
    "\n",
    "# Print shapes for Test 1\n",
    "print(f\"Test 1 - single image tensor shape: {imgs[0].shape}\")\n",
    "print(f\"Test 1 - label tensor: {labels}\")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, num_samples, figsize=(16, 4))\n",
    "for i in range(num_samples):\n",
    "    img = imgs[i].permute(1, 2, 0).numpy()\n",
    "    label_name = dataset_test1.label_encoder.inverse_transform([labels[i].item()])[0]\n",
    "\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"{label_name}\\n{sample_ids[i]}\")\n",
    "    axes[i].axis(\"off\")\n",
    "plt.suptitle(\n",
    "    \"PathologyDataset - Whole Images (First Batch)\",\n",
    "    fontsize=14,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Test 2: With patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: With patches (random patches)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Test 2: Patch-based Images\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "dataset_patches = PathologyDataset(\n",
    "    data_dir=TRAIN_DATA_DIR,\n",
    "    labels_df=train_df,\n",
    "    transform=test1_transform,  # Reuse transform from Test 1\n",
    "    use_mask=True,\n",
    "    use_patches=True,\n",
    "    patch_size=32,\n",
    "    num_patches=16,\n",
    "    patch_strategy=\"random\",\n",
    "    min_tissue_ratio=0.05,\n",
    "    use_stain_norm=False,\n",
    "    is_test=False,\n",
    ")\n",
    "\n",
    "# Fetch patches for a specific sample (e.g., index 0)\n",
    "idx = 0\n",
    "patches_batch, label_tensor = dataset_patches[idx]  # [num_patches, C, H, W]\n",
    "sample_id = dataset_patches.samples[idx]\n",
    "label_name = dataset_patches.label_encoder.inverse_transform([label_tensor.item()])[0]\n",
    "\n",
    "# Print shapes for Test 2\n",
    "print(f\"Sample: {sample_id} ({label_name})\")\n",
    "print(f\"Test 2 - patches tensor shape: {patches_batch.shape}\")\n",
    "print(f\"Test 2 - label tensor: {label_tensor}\")\n",
    "\n",
    "# Plot patches\n",
    "fig, axes = plt.subplots(2, 8, figsize=(20, 6))\n",
    "\n",
    "for i in range(16):\n",
    "    row = i // 8\n",
    "    col = i % 8\n",
    "    if i < len(patches_batch):\n",
    "        img = patches_batch[i].permute(1, 2, 0).numpy()\n",
    "        axes[row, col].imshow(img)\n",
    "    axes[row, col].set_title(f\"Patch {i}\")\n",
    "    axes[row, col].axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"PathologyDataset - Patches from {sample_id} ({label_name})\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Test 3: Grid-based patch extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Grid-based patch extraction\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Test 3: Grid-based Patch Extraction\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "dataset_grid = PathologyDataset(\n",
    "    data_dir=TRAIN_DATA_DIR,\n",
    "    labels_df=train_df,\n",
    "    transform=test1_transform,\n",
    "    use_mask=True,\n",
    "    use_patches=True,\n",
    "    patch_size=64,\n",
    "    num_patches=16,\n",
    "    patch_strategy=\"grid\",\n",
    "    min_tissue_ratio=0.05,\n",
    "    use_stain_norm=False,\n",
    "    is_test=False,\n",
    ")\n",
    "\n",
    "# Fetch patches for a specific sample\n",
    "idx = 0\n",
    "patches_batch, label_tensor = dataset_grid[idx]\n",
    "sample_id = dataset_grid.samples[idx]\n",
    "label_name = dataset_grid.label_encoder.inverse_transform([label_tensor.item()])[0]\n",
    "\n",
    "# Print shapes\n",
    "print(f\"Sample: {sample_id} ({label_name})\")\n",
    "print(f\"Test 3 - patches tensor shape: {patches_batch.shape}\")\n",
    "print(f\"Test 3 - label tensor: {label_tensor}\")\n",
    "\n",
    "# Plot patches\n",
    "fig, axes = plt.subplots(2, 8, figsize=(20, 6))\n",
    "\n",
    "for i in range(16):\n",
    "    row = i // 8\n",
    "    col = i % 8\n",
    "    if i < len(patches_batch):\n",
    "        img = patches_batch[i].permute(1, 2, 0).numpy()\n",
    "        axes[row, col].imshow(img)\n",
    "    axes[row, col].set_title(f\"Patch {i}\")\n",
    "    axes[row, col].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"PathologyDataset - Grid Patches from {sample_id} ({label_name})\", fontsize=14\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Train the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_balanced_batch(dataset, num_classes=4, samples_per_class=4):\n",
    "    \"\"\"\n",
    "    Construct a balanced batch from the dataset.\n",
    "    \"\"\"\n",
    "    selected_indices = []\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        all_indices = np.where(dataset.encoded_labels == class_idx)[0]\n",
    "\n",
    "        if len(all_indices) >= samples_per_class:\n",
    "            chosen = np.random.choice(all_indices, samples_per_class, replace=False)\n",
    "        else:\n",
    "            chosen = np.random.choice(all_indices, samples_per_class, replace=True)\n",
    "\n",
    "        selected_indices.extend(chosen)\n",
    "\n",
    "    np.random.shuffle(selected_indices)\n",
    "\n",
    "    batch_patches = []\n",
    "    batch_labels = []\n",
    "\n",
    "    print(f\"Constructing balanced batch with {len(selected_indices)} samples...\")\n",
    "    for idx in selected_indices:\n",
    "        p, l = dataset[idx]\n",
    "        batch_patches.append(p)\n",
    "        batch_labels.append(l)\n",
    "\n",
    "    patches_tensor = torch.stack(batch_patches)\n",
    "    labels_tensor = torch.stack(batch_labels)\n",
    "\n",
    "    return patches_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Plot the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = PathologyDataset(\n",
    "    data_dir=TRAIN_DATA_DIR,\n",
    "    labels_df=train_df,\n",
    "    transform=test1_transform,\n",
    "    use_mask=True,\n",
    "    use_patches=True,\n",
    "    patch_size=64,\n",
    "    num_patches=16,\n",
    "    patch_strategy=\"random\",\n",
    "    min_tissue_ratio=0.05,\n",
    "    use_stain_norm=False,\n",
    "    is_test=False,\n",
    ")\n",
    "\n",
    "# Create DataLoader with batch_size=16\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "patches, labels = get_balanced_batch(train_dataset, num_classes=4, samples_per_class=4)\n",
    "# patches shape: [Batch_Size, Num_Patches, 3, H, W] -> [16, 16, 3, 224, 224]\n",
    "# labels shape: [Batch_Size] -> [16]\n",
    "\n",
    "print(f\"Input batch shape: {patches.shape}\")\n",
    "print(f\"Labels batch shape: {labels.shape}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "print(\n",
    "    f\"Label names: {[train_dataset.label_encoder.inverse_transform([label.item()])[0] for label in labels]}\"\n",
    ")\n",
    "\n",
    "# Plot the first batch (show first 4 images with their 16 patches each)\n",
    "num_samples_to_plot = 4\n",
    "fig, axes = plt.subplots(\n",
    "    num_samples_to_plot, 16, figsize=(24, num_samples_to_plot * 1.5)\n",
    ")\n",
    "\n",
    "for sample_idx in range(num_samples_to_plot):\n",
    "    label_idx = labels[sample_idx].item()\n",
    "    label_name = train_dataset.label_encoder.inverse_transform([label_idx])[0]\n",
    "\n",
    "    for patch_idx in range(16):\n",
    "        ax = axes[sample_idx, patch_idx] if num_samples_to_plot > 1 else axes[patch_idx]\n",
    "\n",
    "        # Get patch and convert to numpy\n",
    "        patch = patches[sample_idx, patch_idx].permute(1, 2, 0).numpy()\n",
    "        ax.imshow(patch)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # Add title only to first patch of each row\n",
    "        if patch_idx == 0:\n",
    "            ax.set_title(f\"{label_name} (Label: {label_idx})\", loc=\"left\", fontsize=10)\n",
    "\n",
    "plt.suptitle(\"First Batch - 4 Samples with 16 Patches Each\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Train simple CNN using first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a simple and fast CNN model\n",
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self, num_classes=4):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             # Conv block 1\n",
    "#             nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             # Conv block 2\n",
    "#             nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             # Conv block 3\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#         )\n",
    "\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.AdaptiveAvgPool2d((1, 1)),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(64, num_classes),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# # 2. Define Model (Simple CNN)\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# num_classes = len(train_dataset.label_encoder.classes_)\n",
    "# model = SimpleCNN(num_classes=num_classes)\n",
    "# model = model.to(device)\n",
    "\n",
    "# print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# # 3. Define Loss and Optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # 4. Train on the First Batch\n",
    "# print(\"\\n\" + \"=\" * 50)\n",
    "# print(\"Overfitting on the First Batch (50 Epochs)\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# model.train()\n",
    "\n",
    "# # Get the first batch\n",
    "# patches, labels = get_balanced_batch(train_dataset, num_classes=4, samples_per_class=4)\n",
    "# # patches shape: [Batch_Size, Num_Patches, 3, H, W] -> [16, 16, 3, 224, 224]\n",
    "# # labels shape: [Batch_Size] -> [16]\n",
    "\n",
    "# print(f\"Input batch shape: {patches.shape}\")\n",
    "# print(f\"Labels batch shape: {labels.shape}\")\n",
    "\n",
    "# # Reshape for CNN: treat every patch as an independent image sharing the bag label\n",
    "# # New shape: [Batch_Size * Num_Patches, 3, H, W]\n",
    "# batch_size, num_patches, c, h, w = patches.shape\n",
    "# inputs = patches.view(-1, c, h, w).to(device)  # Flatten batch and patches dimensions\n",
    "# targets = (\n",
    "#     labels.view(-1, 1).expand(-1, num_patches).reshape(-1).to(device)\n",
    "# )  # Repeat labels for each patch\n",
    "\n",
    "# print(f\"Reshaped inputs for CNN: {inputs.shape}\")\n",
    "# print(f\"Reshaped targets: {targets.shape}\")\n",
    "\n",
    "# # Train for 50 epochs on this single batch\n",
    "# num_epochs = 500\n",
    "# print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     # Forward pass\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(inputs)\n",
    "#     loss = criterion(outputs, targets)\n",
    "\n",
    "#     # Backward pass and optimize\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     # Calculate accuracy\n",
    "#     _, preds = torch.max(outputs, 1)\n",
    "#     acc = (preds == targets).sum().item() / targets.size(0)\n",
    "\n",
    "#     print(\n",
    "#         f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Patch Acc: {acc:.4f}\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Pretrained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "# 1. Setup Dataset and DataLoader\n",
    "# We use the patch-based dataset configuration\n",
    "train_dataset = PathologyDataset(\n",
    "    data_dir=TRAIN_DATA_DIR,\n",
    "    labels_df=train_df,\n",
    "    transform=test1_transform,  # Resize(224) + ToTensor\n",
    "    use_mask=True,\n",
    "    use_patches=True,\n",
    "    patch_size=64,\n",
    "    num_patches=16,\n",
    "    patch_strategy=\"random\",\n",
    "    min_tissue_ratio=0.05,\n",
    "    use_stain_norm=False,\n",
    "    is_test=False,\n",
    ")\n",
    "\n",
    "# Create DataLoader with batch_size=16\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 2. Define Model (Small Pretrained Model - MobileNetV2)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pretrained MobileNetV2 (small and efficient)\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Modify the classifier for our number of classes\n",
    "num_classes = len(train_dataset.label_encoder.classes_)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model: MobileNetV2\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 3. Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 4. Train on the First Batch\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Overfitting on the First Batch (50 Epochs)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Get the first batch\n",
    "data_iter = iter(train_loader)\n",
    "patches, labels = get_balanced_batch(train_dataset, num_classes=4, samples_per_class=2)\n",
    "# patches shape: [Batch_Size, Num_Patches, 3, H, W] -> [16, 16, 3, 224, 224]\n",
    "# labels shape: [Batch_Size] -> [16]\n",
    "\n",
    "print(f\"Input batch shape: {patches.shape}\")\n",
    "print(f\"Labels batch shape: {labels.shape}\")\n",
    "\n",
    "# Reshape for CNN: treat every patch as an independent image sharing the bag label\n",
    "# New shape: [Batch_Size * Num_Patches, 3, H, W]\n",
    "batch_size, num_patches, c, h, w = patches.shape\n",
    "inputs = patches.view(-1, c, h, w).to(device)  # Flatten batch and patches dimensions\n",
    "targets = (\n",
    "    labels.view(-1, 1).expand(-1, num_patches).reshape(-1).to(device)\n",
    ")  # Repeat labels for each patch\n",
    "\n",
    "print(f\"Reshaped inputs for MobileNetV2: {inputs.shape}\")\n",
    "print(f\"Reshaped targets: {targets.shape}\")\n",
    "\n",
    "# Train for 50 epochs on this single batch\n",
    "num_epochs = 50\n",
    "print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    acc = (preds == targets).sum().item() / targets.size(0)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Patch Acc: {acc:.4f}\"\n",
    "        )\n",
    "\n",
    "print(\"\\nTraining completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
