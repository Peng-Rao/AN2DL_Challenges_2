{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(\"../data/train_labels.csv\")\n",
    "label_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 2 samples from each class\n",
    "samples_per_class = 2\n",
    "\n",
    "# Group by label and sample\n",
    "selected_samples = []\n",
    "for label in label_df[\"label\"].unique():\n",
    "    class_samples = label_df[label_df[\"label\"] == label].head(samples_per_class)\n",
    "    selected_samples.append(class_samples)\n",
    "\n",
    "# Combine all selected samples\n",
    "selected_df = pd.concat(selected_samples, ignore_index=True)\n",
    "selected_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Visualize some samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Luminal A samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 4 Luminal A samples with their masks\n",
    "luminal_a_samples = label_df[label_df[\"label\"] == \"Luminal A\"].head(4)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, (_, row) in enumerate(luminal_a_samples.iterrows()):\n",
    "    img_name = row[\"sample_index\"]\n",
    "    img_path = Path(\"../data/train_data\") / img_name\n",
    "\n",
    "    # Remove \"img_\" prefix if present to find mask\n",
    "    mask_name = img_name[4:] if img_name.startswith(\"img_\") else img_name\n",
    "    mask_path = Path(\"../data/train_data\") / f\"mask_{mask_name}\"\n",
    "\n",
    "    # Load original image\n",
    "    image = Image.open(img_path)\n",
    "    axes[0, idx].imshow(image)\n",
    "    axes[0, idx].axis(\"off\")\n",
    "    axes[0, idx].set_title(f\"{img_name}\", fontsize=10)\n",
    "\n",
    "    # Load and display mask\n",
    "    if mask_path.exists():\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        axes[1, idx].imshow(mask, cmap=\"gray\")\n",
    "        axes[1, idx].axis(\"off\")\n",
    "        axes[1, idx].set_title(f\"mask_{mask_name}\", fontsize=10)\n",
    "    else:\n",
    "        axes[1, idx].text(0.5, 0.5, \"No mask\", ha=\"center\", va=\"center\")\n",
    "        axes[1, idx].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Original\", fontsize=12)\n",
    "axes[1, 0].set_ylabel(\"Mask\", fontsize=12)\n",
    "\n",
    "fig.suptitle(\"Luminal A Samples with Masks\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Luminal B samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 4 Luminal B samples with their masks\n",
    "luminal_b_samples = label_df[label_df[\"label\"] == \"Luminal B\"].head(4)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, (_, row) in enumerate(luminal_b_samples.iterrows()):\n",
    "    img_name = row[\"sample_index\"]\n",
    "    img_path = Path(\"../data/train_data\") / img_name\n",
    "\n",
    "    # Remove \"img_\" prefix if present to find mask\n",
    "    mask_name = img_name[4:] if img_name.startswith(\"img_\") else img_name\n",
    "    mask_path = Path(\"../data/train_data\") / f\"mask_{mask_name}\"\n",
    "\n",
    "    # Load original image\n",
    "    image = Image.open(img_path)\n",
    "    axes[0, idx].imshow(image)\n",
    "    axes[0, idx].axis(\"off\")\n",
    "    axes[0, idx].set_title(f\"{img_name}\", fontsize=10)\n",
    "\n",
    "    # Load and display mask\n",
    "    if mask_path.exists():\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        axes[1, idx].imshow(mask, cmap=\"gray\")\n",
    "        axes[1, idx].axis(\"off\")\n",
    "        axes[1, idx].set_title(f\"mask_{mask_name}\", fontsize=10)\n",
    "    else:\n",
    "        axes[1, idx].text(0.5, 0.5, \"No mask\", ha=\"center\", va=\"center\")\n",
    "        axes[1, idx].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Original\", fontsize=12)\n",
    "axes[1, 0].set_ylabel(\"Mask\", fontsize=12)\n",
    "\n",
    "fig.suptitle(\"Luminal B Samples with Masks\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### HER2(+) samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 4 HER2(+) samples with their masks\n",
    "her2_samples = label_df[label_df[\"label\"] == \"HER2(+)\"].head(4)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, (_, row) in enumerate(her2_samples.iterrows()):\n",
    "    img_name = row[\"sample_index\"]\n",
    "    img_path = Path(\"../data/train_data\") / img_name\n",
    "\n",
    "    # Remove \"img_\" prefix if present to find mask\n",
    "    mask_name = img_name[4:] if img_name.startswith(\"img_\") else img_name\n",
    "    mask_path = Path(\"../data/train_data\") / f\"mask_{mask_name}\"\n",
    "\n",
    "    # Load original image\n",
    "    image = Image.open(img_path)\n",
    "    axes[0, idx].imshow(image)\n",
    "    axes[0, idx].axis(\"off\")\n",
    "    axes[0, idx].set_title(f\"{img_name}\", fontsize=10)\n",
    "\n",
    "    # Load and display mask\n",
    "    if mask_path.exists():\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        axes[1, idx].imshow(mask, cmap=\"gray\")\n",
    "        axes[1, idx].axis(\"off\")\n",
    "        axes[1, idx].set_title(f\"mask_{mask_name}\", fontsize=10)\n",
    "    else:\n",
    "        axes[1, idx].text(0.5, 0.5, \"No mask\", ha=\"center\", va=\"center\")\n",
    "        axes[1, idx].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Original\", fontsize=12)\n",
    "axes[1, 0].set_ylabel(\"Mask\", fontsize=12)\n",
    "\n",
    "fig.suptitle(\"HER2(+) Samples with Masks\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Triple negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 4 Triple negative samples with their masks\n",
    "triple_negative_samples = label_df[label_df[\"label\"] == \"Triple negative\"].head(4)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, (_, row) in enumerate(triple_negative_samples.iterrows()):\n",
    "    img_name = row[\"sample_index\"]\n",
    "    img_path = Path(\"../data/train_data\") / img_name\n",
    "\n",
    "    # Remove \"img_\" prefix if present to find mask\n",
    "    mask_name = img_name[4:] if img_name.startswith(\"img_\") else img_name\n",
    "    mask_path = Path(\"../data/train_data\") / f\"mask_{mask_name}\"\n",
    "\n",
    "    # Load original image\n",
    "    image = Image.open(img_path)\n",
    "    axes[0, idx].imshow(image)\n",
    "    axes[0, idx].axis(\"off\")\n",
    "    axes[0, idx].set_title(f\"{img_name}\", fontsize=10)\n",
    "\n",
    "    # Load and display mask\n",
    "    if mask_path.exists():\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        axes[1, idx].imshow(mask, cmap=\"gray\")\n",
    "        axes[1, idx].axis(\"off\")\n",
    "        axes[1, idx].set_title(f\"mask_{mask_name}\", fontsize=10)\n",
    "    else:\n",
    "        axes[1, idx].text(0.5, 0.5, \"No mask\", ha=\"center\", va=\"center\")\n",
    "        axes[1, idx].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Original\", fontsize=12)\n",
    "axes[1, 0].set_ylabel(\"Mask\", fontsize=12)\n",
    "\n",
    "fig.suptitle(\"Triple Negative Samples with Masks\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Apply the mask to the original image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask_to_image(img_name, img_dir=\"../data/train_data\", threshold=100):\n",
    "    \"\"\"\n",
    "    Apply binary mask to an image to remove background.\n",
    "\n",
    "    Args:\n",
    "        img_name: str, image filename (e.g., \"img_0000.png\" or \"0000.png\")\n",
    "        img_dir: str, directory containing images and masks (default: \"data/train_data\")\n",
    "        threshold: int, threshold value for binarizing mask (default: 100)\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Masked image with background removed\n",
    "    \"\"\"\n",
    "    img_dir = Path(img_dir)\n",
    "\n",
    "    # Construct image path\n",
    "    img_path = img_dir / img_name\n",
    "\n",
    "    # Load original image\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    # Remove \"img_\" prefix if present to find mask\n",
    "    mask_name = img_name[4:] if img_name.startswith(\"img_\") else img_name\n",
    "    mask_path = img_dir / f\"mask_{mask_name}\"\n",
    "\n",
    "    # Check if mask exists\n",
    "    if not mask_path.exists():\n",
    "        print(f\"Warning: Mask not found for {img_name}\")\n",
    "        return image\n",
    "\n",
    "    # Load mask\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "    # Resize mask if necessary\n",
    "    if mask.size != image.size:\n",
    "        mask = mask.resize(image.size, resample=Image.NEAREST)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    image_np = np.array(image)\n",
    "    mask_np = np.array(mask)\n",
    "\n",
    "    # Create binary mask\n",
    "    mask_binary = (mask_np > threshold).astype(np.uint8)\n",
    "\n",
    "    # Expand mask to 3 channels for RGB image\n",
    "    mask_3ch = np.stack([mask_binary] * 3, axis=-1)\n",
    "\n",
    "    # Apply mask\n",
    "    image_masked = image_np * mask_3ch\n",
    "\n",
    "    # Convert back to PIL Image\n",
    "    masked_image = Image.fromarray(image_masked.astype(np.uint8))\n",
    "\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the apply_mask_to_image function\n",
    "img_name = \"0000.png\"\n",
    "img_path = Path(\"../data/train_data\") / f\"img_{img_name}\"\n",
    "mask_path = Path(\"../data/train_data\") / f\"mask_{img_name}\"\n",
    "\n",
    "# Load original image and mask\n",
    "original_image = Image.open(img_path).convert(\"RGB\")\n",
    "mask_image = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "# Apply mask using the function\n",
    "masked_image = apply_mask_to_image(f\"img_{img_name}\", threshold=100)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(original_image)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(mask_image, cmap=\"gray\")\n",
    "axes[1].set_title(\"Mask\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(masked_image)\n",
    "axes[2].set_title(\"Masked Image\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare original and masked images\n",
    "img_name = \"0109.png\"\n",
    "\n",
    "img_path = Path(\"../data/train_data\") / f\"img_{img_name}\"\n",
    "mask_path = Path(\"../data/train_data\") / f\"mask_{img_name}\"\n",
    "# Load original image and mask\n",
    "original_image = Image.open(img_path).convert(\"RGB\")\n",
    "mask_image = Image.open(mask_path).convert(\"L\")\n",
    "# Apply mask using the function\n",
    "masked_image = apply_mask_to_image(f\"img_{img_name}\", threshold=100)\n",
    "\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(original_image)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(mask_image, cmap=\"gray\")\n",
    "axes[1].set_title(\"Mask\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(masked_image)\n",
    "axes[2].set_title(\"Masked Image\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Data Augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Image resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test image resize transformation using Albumentations for 4 classes (1 sample per class)\n",
    "# Define resize transformation with Albumentations\n",
    "resize_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get one sample from each class\n",
    "samples_per_class = {}\n",
    "for label in label_df[\"label\"].unique():\n",
    "    class_sample = label_df[label_df[\"label\"] == label].iloc[0]\n",
    "    samples_per_class[label] = class_sample[\"sample_index\"]\n",
    "\n",
    "# Visualize original vs resized images\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, (label, img_name) in enumerate(samples_per_class.items()):\n",
    "    # Load original image\n",
    "    img_path = Path(\"../data/train_data\") / img_name\n",
    "    original_image = Image.open(img_path).convert(\"RGB\")\n",
    "    original_np = np.array(original_image)\n",
    "\n",
    "    # Apply Albumentations transformation\n",
    "    transformed = resize_transform(image=original_np)\n",
    "    resized_tensor = transformed[\"image\"]\n",
    "\n",
    "    # Plot original\n",
    "    axes[0, idx].imshow(original_image)\n",
    "    axes[0, idx].set_title(\n",
    "        f\"{label}\\n{img_name}\\nSize: {original_image.size}\", fontsize=9\n",
    "    )\n",
    "    axes[0, idx].axis(\"off\")\n",
    "\n",
    "    # Plot resized (denormalize and convert tensor back to displayable format)\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    resized_display = resized_tensor.permute(1, 2, 0).numpy()\n",
    "    resized_display = std * resized_display + mean\n",
    "    resized_display = np.clip(resized_display, 0, 1)\n",
    "\n",
    "    axes[1, idx].imshow(resized_display)\n",
    "    axes[1, idx].set_title(\n",
    "        f\"Resized: {resized_tensor.shape[1]}x{resized_tensor.shape[2]}\", fontsize=9\n",
    "    )\n",
    "    axes[1, idx].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Original\", fontsize=12)\n",
    "axes[1, 0].set_ylabel(\"Resized (224x224)\", fontsize=12)\n",
    "\n",
    "fig.suptitle(\"Albumentations Resize Transformation (1 Sample per Class)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Color Jitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Color Jitter transformation using Albumentations for 4 classes (1 sample per class)\n",
    "# Define color jitter transformation with Albumentations\n",
    "color_jitter_transform = A.Compose(\n",
    "    [\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=1.0),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get one sample from each class\n",
    "samples_per_class = {}\n",
    "for label in label_df[\"label\"].unique():\n",
    "    class_sample = label_df[label_df[\"label\"] == label].iloc[0]\n",
    "    samples_per_class[label] = class_sample[\"sample_index\"]\n",
    "\n",
    "# Visualize original vs color jittered images\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, (label, img_name) in enumerate(samples_per_class.items()):\n",
    "    # Load original image\n",
    "    img_path = Path(\"../data/train_data\") / img_name\n",
    "    original_image = Image.open(img_path).convert(\"RGB\")\n",
    "    original_np = np.array(original_image)\n",
    "\n",
    "    # Apply Color Jitter transformation\n",
    "    transformed = color_jitter_transform(image=original_np)\n",
    "    jittered_image = transformed[\"image\"]\n",
    "\n",
    "    # Plot original\n",
    "    axes[0, idx].imshow(original_image)\n",
    "    axes[0, idx].set_title(f\"{label}\\n{img_name}\", fontsize=9)\n",
    "    axes[0, idx].axis(\"off\")\n",
    "\n",
    "    # Plot color jittered\n",
    "    axes[1, idx].imshow(jittered_image)\n",
    "    axes[1, idx].set_title(\"Color Jittered\", fontsize=9)\n",
    "    axes[1, idx].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Original\", fontsize=12)\n",
    "axes[1, 0].set_ylabel(\"Color Jitter\", fontsize=12)\n",
    "\n",
    "fig.suptitle(\"Color Jitter Transformation (1 Sample per Class)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Split masked image to multiple patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image_to_patches(\n",
    "    image, mask, patch_size=224, overlap=0, min_tissue_ratio=0.5, threshold=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Split an image into multiple patches, filtering by tissue content.\n",
    "\n",
    "    Args:\n",
    "        image: PIL Image or numpy array (RGB image)\n",
    "        mask: PIL Image or numpy array (grayscale mask)\n",
    "        patch_size: int, size of each square patch (default: 224)\n",
    "        overlap: int, overlap between patches in pixels (default: 0)\n",
    "        min_tissue_ratio: float, minimum ratio of tissue pixels required (default: 0.5)\n",
    "        threshold: int, threshold value for binarizing mask (default: 100)\n",
    "\n",
    "    Returns:\n",
    "        list of PIL Images: List of valid image patches\n",
    "        list of tuples: List of (x, y) coordinates for each patch\n",
    "        list of float: List of tissue ratios for each patch\n",
    "    \"\"\"\n",
    "    # Convert to numpy if needed\n",
    "    if isinstance(image, Image.Image):\n",
    "        img_np = np.array(image)\n",
    "    else:\n",
    "        img_np = image\n",
    "\n",
    "    if isinstance(mask, Image.Image):\n",
    "        mask_np = np.array(mask)\n",
    "    else:\n",
    "        mask_np = mask\n",
    "\n",
    "    # Ensure mask is grayscale\n",
    "    if len(mask_np.shape) == 3:\n",
    "        mask_np = mask_np[:, :, 0]\n",
    "\n",
    "    # Create binary mask\n",
    "    mask_binary = (mask_np > threshold).astype(np.uint8)\n",
    "\n",
    "    height, width = img_np.shape[:2]\n",
    "    stride = patch_size - overlap\n",
    "\n",
    "    patches = []\n",
    "    coordinates = []\n",
    "    tissue_ratios = []\n",
    "\n",
    "    total_patch_pixels = patch_size * patch_size\n",
    "\n",
    "    # Iterate over the image with the specified stride\n",
    "    for y in range(0, height - patch_size + 1, stride):\n",
    "        for x in range(0, width - patch_size + 1, stride):\n",
    "            # Extract mask patch\n",
    "            mask_patch = mask_binary[y : y + patch_size, x : x + patch_size]\n",
    "\n",
    "            # Calculate tissue ratio\n",
    "            tissue_pixels = np.sum(mask_patch)\n",
    "            tissue_ratio = tissue_pixels / total_patch_pixels\n",
    "\n",
    "            # Only keep patches with sufficient tissue content\n",
    "            if tissue_ratio >= min_tissue_ratio:\n",
    "                # Extract image patch\n",
    "                img_patch = img_np[y : y + patch_size, x : x + patch_size]\n",
    "\n",
    "                # Convert to PIL Image\n",
    "                patch_img = Image.fromarray(img_patch.astype(np.uint8))\n",
    "                patches.append(patch_img)\n",
    "                coordinates.append((x, y))\n",
    "                tissue_ratios.append(tissue_ratio)\n",
    "\n",
    "    return patches, coordinates, tissue_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Macenko normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubtypeDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_dir: str,\n",
    "        train_labels_path: str,\n",
    "        mode: str,\n",
    "        transform=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_dir (str): Directory with all the images.\n",
    "            train_labels_path (str): Path to the CSV file with training labels.\n",
    "            mode (str): One of 'train' or 'test'.\n",
    "            transform: Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "        assert mode in [\"train\", \"test\"], \"mode must be 'train', or 'test'\"\n",
    "        self.mode = mode\n",
    "\n",
    "        self.label_to_idx = {}\n",
    "        self.idx_to_label = {}\n",
    "\n",
    "        if not self.mode == \"test\":\n",
    "            # If in training mode, load labels\n",
    "            if train_labels_path is None:\n",
    "                raise ValueError(\"Training mode requires a train_labels_path!\")\n",
    "\n",
    "            df = pd.read_csv(train_labels_path)\n",
    "            self.img_ids = df.iloc[:, 0].values\n",
    "            self.labels = df.iloc[:, 1].values\n",
    "\n",
    "            # Create label mappings\n",
    "            unique_labels = sorted(list(set(self.labels)))\n",
    "            self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "            self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
    "\n",
    "            print(f\"Label Mapping: {self.label_to_idx}\")\n",
    "\n",
    "        else:\n",
    "            # Test mode: load all image ids from directory\n",
    "            self.img_ids = sorted(\n",
    "                [\n",
    "                    f.name\n",
    "                    for f in self.img_dir.iterdir()\n",
    "                    if f.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]\n",
    "                    and not f.name.startswith(\"mask_\")\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def _load_masked_image(self, img_name):\n",
    "        \"\"\"Load image and apply mask to remove background\"\"\"\n",
    "        img_path = self.img_dir / img_name\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Remove \"img_\" prefix if present\n",
    "        if img_name.startswith(\"img_\"):\n",
    "            img_name = img_name[4:]\n",
    "\n",
    "        # Find corresponding mask\n",
    "        mask_name = f\"mask_{img_name}\"\n",
    "        mask_path = self.img_dir / mask_name\n",
    "\n",
    "        if mask_path.exists():\n",
    "            try:\n",
    "                mask = Image.open(mask_path).convert(\"L\")\n",
    "                if mask.size != image.size:\n",
    "                    mask = mask.resize(image.size, resample=Image.NEAREST)\n",
    "\n",
    "                mask_np = np.array(mask)\n",
    "                mask_binary = (mask_np > 100).astype(np.uint8)\n",
    "                mask_3ch = np.stack([mask_binary] * 3, axis=-1)\n",
    "\n",
    "                image_np = np.array(image)\n",
    "                image_masked = image_np * mask_3ch\n",
    "                image = Image.fromarray(image_masked)\n",
    "            except Exception as e:\n",
    "                print(f\"Error applying mask for {img_name}: {e}\")\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_ids[idx]\n",
    "\n",
    "        # Load and apply mask\n",
    "        image = self._load_masked_image(img_name)\n",
    "\n",
    "        # Apply Transforms (Resize, Tensor, Norm)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.mode == \"test\":\n",
    "            return image, img_name\n",
    "        else:\n",
    "            label_str = self.labels[idx]\n",
    "            label_idx = self.label_to_idx[label_str]\n",
    "            return image, torch.tensor(label_idx, dtype=torch.long)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
