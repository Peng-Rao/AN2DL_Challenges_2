{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install necessary packages\n",
    "!pip install gdown lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Get data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=19o_R8S5f09XFXZIk_F1B7nui7TxNq9mH\n",
    "!unzip -q data.zip\n",
    "!mv an2dl2526c2 data\n",
    "!ls -l data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the trash list\n",
    "!gdown https://drive.google.com/uc?id=1Hp0nKCW6DNDVCvWYGLGkahQFc4xtu4eu\n",
    "!mv trash_list.txt data/trash_list.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics import AUROC, Accuracy, ConfusionMatrix, F1Score\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Utilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Data paths\n",
    "    DATA_DIR = \"./data\"\n",
    "    TRAIN_DATA_DIR = \"./data/train_data\"\n",
    "    TEST_DATA_DIR = \"./data/test_data\"\n",
    "    TRAIN_LABELS_PATH = \"./data/train_labels.csv\"\n",
    "    OUTPUT_PATH = \"./predictions.csv\"\n",
    "    # Class labels\n",
    "    CLASSES = [\"Luminal A\", \"Luminal B\", \"HER2(+)\", \"Triple negative\"]\n",
    "    NUM_CLASSES = 4\n",
    "\n",
    "    # Image settings\n",
    "    IMG_SIZE = 512  # Larger size for histopathology\n",
    "    USE_MASK = True\n",
    "\n",
    "    # Tissue detection settings\n",
    "    TISSUE_THRESHOLD = 0.8  # Threshold for tissue detection (lower = more sensitive)\n",
    "    MIN_TISSUE_AREA = 0.05  # Minimum tissue area ratio\n",
    "    PADDING = 50  # Padding around tissue bounding box\n",
    "\n",
    "    # Patch-based settings (for very large images)\n",
    "    USE_PATCHES = True\n",
    "    PATCH_SIZE = 224\n",
    "    NUM_PATCHES = 16  # Number of patches to sample per image\n",
    "\n",
    "    # Stain normalization\n",
    "    USE_STAIN_NORMALIZATION = False\n",
    "\n",
    "    # Training settings\n",
    "    BATCH_SIZE = 16\n",
    "    NUM_WORKERS = 2\n",
    "    MAX_EPOCHS = 50\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "\n",
    "    # Validation split\n",
    "    VAL_SPLIT = 0.2\n",
    "    RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Extract tissue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TissueExtractor:\n",
    "    \"\"\"\n",
    "    Extract patches from images using existing masks.\n",
    "    Designed for workflow where ground truth masks are already available.\n",
    "\n",
    "    Args:\n",
    "        patch_size: Size of the square patch to extract.\n",
    "        min_tissue_ratio: Minimum ratio of tissue pixels required in a patch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patch_size: int = 224, min_tissue_ratio: float = 0.05):\n",
    "        self.patch_size = patch_size\n",
    "        self.min_tissue_ratio = min_tissue_ratio\n",
    "\n",
    "    def get_valid_patches(\n",
    "        self,\n",
    "        img: np.ndarray,\n",
    "        mask: np.ndarray,\n",
    "        num_patches: int = 8,\n",
    "        strategy: str = \"random\",  # 'random' or 'grid'\n",
    "        stride: int = None,  # For grid strategy: step size between patches\n",
    "        shuffle: bool = True,  # For grid strategy: shuffle valid patches before selecting\n",
    "    ) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img: RGB image (H, W, 3)\n",
    "            mask: Binary or Index mask (H, W). Assumes tissue > 0.\n",
    "            num_patches: Number of patches to extract per image.\n",
    "            strategy: 'random' samples points from mask; 'grid' slides across image.\n",
    "            stride: Step size for grid strategy. Defaults to patch_size (no overlap).\n",
    "            shuffle: Whether to shuffle grid patches before selecting (for diversity).\n",
    "\n",
    "        Returns:\n",
    "            images: List of RGB patches\n",
    "            masks: List of corresponding Mask patches\n",
    "        \"\"\"\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # if mask has 3 channels, convert to single channel\n",
    "        if len(mask.shape) == 3:\n",
    "            mask = mask[:, :, 0]\n",
    "\n",
    "        # Find all tissue pixel indices\n",
    "        tissue_indices = np.where(mask > 0)\n",
    "\n",
    "        # If no tissue found, return empty lists\n",
    "        if len(tissue_indices[0]) == 0:\n",
    "            print(\"Warning: No tissue found in mask!\")\n",
    "            return [], []\n",
    "\n",
    "        if strategy == \"random\":\n",
    "            return self._extract_random(img, mask, tissue_indices, num_patches, h, w)\n",
    "        elif strategy == \"grid\":\n",
    "            return self._extract_grid(img, mask, num_patches, h, w, stride, shuffle)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown strategy: {strategy}. Use 'random' or 'grid'.\")\n",
    "\n",
    "    def _extract_random(\n",
    "        self,\n",
    "        img: np.ndarray,\n",
    "        mask: np.ndarray,\n",
    "        tissue_indices: Tuple[np.ndarray, np.ndarray],\n",
    "        num_patches: int,\n",
    "        h: int,\n",
    "        w: int,\n",
    "    ) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "        \"\"\"Random sampling strategy: randomly select tissue pixels as patch centers.\"\"\"\n",
    "\n",
    "        patches_img = []\n",
    "        patches_mask = []\n",
    "\n",
    "        # Protection mechanism: limit the number of attempts to avoid infinite loop\n",
    "        attempts = 0\n",
    "        max_attempts = num_patches * 50\n",
    "\n",
    "        while len(patches_img) < num_patches and attempts < max_attempts:\n",
    "            attempts += 1\n",
    "\n",
    "            # Randomly select a tissue pixel as center\n",
    "            idx = np.random.randint(len(tissue_indices[0]))\n",
    "            cy, cx = tissue_indices[0][idx], tissue_indices[1][idx]\n",
    "\n",
    "            # Calculate top-left and bottom-right corners to ensure no out-of-bounds\n",
    "            half_size = self.patch_size // 2\n",
    "\n",
    "            # Simple center cropping logic\n",
    "            y_min = int(cy - half_size)\n",
    "            x_min = int(cx - half_size)\n",
    "            y_max = y_min + self.patch_size\n",
    "            x_max = x_min + self.patch_size\n",
    "\n",
    "            # Boundary check: if the patch goes out of image bounds, skip and retry\n",
    "            if y_min < 0 or x_min < 0 or y_max > h or x_max > w:\n",
    "                continue\n",
    "\n",
    "            # Extract Mask Patch for validation\n",
    "            mask_patch = mask[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            # Calculate the proportion of non-zero pixels\n",
    "            current_ratio = np.count_nonzero(mask_patch) / mask_patch.size\n",
    "\n",
    "            if current_ratio >= self.min_tissue_ratio:\n",
    "                # Extract Image Patch\n",
    "                img_patch = img[y_min:y_max, x_min:x_max]\n",
    "\n",
    "                patches_img.append(img_patch)\n",
    "                patches_mask.append(mask_patch)\n",
    "\n",
    "        return patches_img, patches_mask\n",
    "\n",
    "    def _extract_grid(\n",
    "        self,\n",
    "        img: np.ndarray,\n",
    "        mask: np.ndarray,\n",
    "        num_patches: int,\n",
    "        h: int,\n",
    "        w: int,\n",
    "        stride: int = None,\n",
    "        shuffle: bool = True,\n",
    "    ) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Grid strategy: systematically slide across the image.\n",
    "\n",
    "        Args:\n",
    "            img: RGB image\n",
    "            mask: Binary mask\n",
    "            num_patches: Maximum number of patches to extract\n",
    "            h, w: Image dimensions\n",
    "            stride: Step size between patches. Defaults to patch_size (no overlap).\n",
    "            shuffle: If True, shuffle valid patches before selecting to add diversity.\n",
    "        \"\"\"\n",
    "\n",
    "        if stride is None:\n",
    "            stride = self.patch_size  # No overlap by default\n",
    "\n",
    "        # Calculate all valid grid positions\n",
    "        y_positions = list(range(0, h - self.patch_size + 1, stride))\n",
    "        x_positions = list(range(0, w - self.patch_size + 1, stride))\n",
    "\n",
    "        # Collect all valid patches first\n",
    "        valid_patches = []  # List of (y_min, x_min, tissue_ratio)\n",
    "\n",
    "        for y_min in y_positions:\n",
    "            for x_min in x_positions:\n",
    "                y_max = y_min + self.patch_size\n",
    "                x_max = x_min + self.patch_size\n",
    "\n",
    "                # Extract mask patch for validation\n",
    "                mask_patch = mask[y_min:y_max, x_min:x_max]\n",
    "\n",
    "                # Calculate tissue ratio\n",
    "                tissue_ratio = np.count_nonzero(mask_patch) / mask_patch.size\n",
    "\n",
    "                if tissue_ratio >= self.min_tissue_ratio:\n",
    "                    valid_patches.append((y_min, x_min, tissue_ratio))\n",
    "\n",
    "        # Shuffle or sort based on preference\n",
    "        if shuffle:\n",
    "            np.random.shuffle(valid_patches)\n",
    "        else:\n",
    "            # Sort by tissue ratio (descending) to prioritize patches with more tissue\n",
    "            valid_patches.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "        # Extract the requested number of patches\n",
    "        patches_img = []\n",
    "        patches_mask = []\n",
    "\n",
    "        for y_min, x_min, _ in valid_patches[:num_patches]:\n",
    "            y_max = y_min + self.patch_size\n",
    "            x_max = x_min + self.patch_size\n",
    "\n",
    "            img_patch = img[y_min:y_max, x_min:x_max]\n",
    "            mask_patch = mask[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            patches_img.append(img_patch)\n",
    "            patches_mask.append(mask_patch)\n",
    "\n",
    "        return patches_img, patches_mask\n",
    "\n",
    "    def get_all_valid_patches(\n",
    "        self,\n",
    "        img: np.ndarray,\n",
    "        mask: np.ndarray,\n",
    "        stride: int = None,\n",
    "    ) -> Tuple[List[np.ndarray], List[np.ndarray], List[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Extract ALL valid patches from the image using grid strategy.\n",
    "        Useful for inference or when you need complete coverage.\n",
    "\n",
    "        Args:\n",
    "            img: RGB image (H, W, 3)\n",
    "            mask: Binary or Index mask (H, W)\n",
    "            stride: Step size between patches. Defaults to patch_size.\n",
    "\n",
    "        Returns:\n",
    "            images: List of RGB patches\n",
    "            masks: List of corresponding mask patches\n",
    "            coordinates: List of (y_min, x_min) for each patch\n",
    "        \"\"\"\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        if len(mask.shape) == 3:\n",
    "            mask = mask[:, :, 0]\n",
    "\n",
    "        if stride is None:\n",
    "            stride = self.patch_size\n",
    "\n",
    "        y_positions = list(range(0, h - self.patch_size + 1, stride))\n",
    "        x_positions = list(range(0, w - self.patch_size + 1, stride))\n",
    "\n",
    "        patches_img = []\n",
    "        patches_mask = []\n",
    "        coordinates = []\n",
    "\n",
    "        for y_min in y_positions:\n",
    "            for x_min in x_positions:\n",
    "                y_max = y_min + self.patch_size\n",
    "                x_max = x_min + self.patch_size\n",
    "\n",
    "                mask_patch = mask[y_min:y_max, x_min:x_max]\n",
    "                tissue_ratio = np.count_nonzero(mask_patch) / mask_patch.size\n",
    "\n",
    "                if tissue_ratio >= self.min_tissue_ratio:\n",
    "                    img_patch = img[y_min:y_max, x_min:x_max]\n",
    "                    patches_img.append(img_patch)\n",
    "                    patches_mask.append(mask_patch)\n",
    "                    coordinates.append((y_min, x_min))\n",
    "\n",
    "        return patches_img, patches_mask, coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Custom dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathologyDataset(Dataset):\n",
    "    \"\"\"Dataset optimized for histopathology images.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Directory containing images and masks.\n",
    "        labels_df: DataFrame with 'sample_index' and 'label' columns for training/validation.\n",
    "        transform: torchvision transforms to apply to images.\n",
    "        img_size: Target size to resize images to (img_size x img_size). If using patches, this is ignored.\n",
    "        use_mask: Whether to use existing masks for tissue extraction.\n",
    "        use_patches: Whether to load images as patches.\n",
    "        patch_size: Size of each patch if using patches.\n",
    "        num_patches: Number of patches to extract per image.\n",
    "        patch_strategy: Strategy for patch extraction ('random' or 'grid').\n",
    "        min_tissue_ratio: Minimum tissue ratio for valid patches.\n",
    "        use_stain_norm: Whether to apply stain normalization.\n",
    "        is_test: Whether the dataset is for testing (no labels).\n",
    "        label_encoder: Optional LabelEncoder for encoding labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        labels_df: Optional[pd.DataFrame] = None,\n",
    "        transform: Optional[transforms.Compose] = None,\n",
    "        use_mask: bool = True,\n",
    "        use_patches: bool = False,\n",
    "        patch_size: int = 224,\n",
    "        num_patches: int = 8,\n",
    "        patch_strategy: str = \"random\",\n",
    "        min_tissue_ratio: float = 0.05,\n",
    "        use_stain_norm: bool = True,\n",
    "        is_test: bool = False,\n",
    "        label_encoder: Optional[LabelEncoder] = None,\n",
    "    ):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.use_mask = use_mask\n",
    "        self.use_patches = use_patches\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "        self.patch_strategy = patch_strategy\n",
    "        self.use_stain_norm = use_stain_norm\n",
    "        self.is_test = is_test\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "        # Initialize helpers\n",
    "        self.tissue_extractor = TissueExtractor(\n",
    "            patch_size=patch_size,\n",
    "            min_tissue_ratio=min_tissue_ratio,\n",
    "        )\n",
    "        self.stain_normalizer = None if use_stain_norm else None\n",
    "\n",
    "        if is_test:\n",
    "            self.samples = self._get_test_samples()\n",
    "            self.labels = None\n",
    "            self.encoded_labels = None\n",
    "        else:\n",
    "            if labels_df is None:\n",
    "                raise ValueError(\"labels_df must be provided for training/validation.\")\n",
    "\n",
    "            self.samples = [\n",
    "                self._clean_sample_idx(str(idx))\n",
    "                for idx in labels_df[\"sample_index\"].tolist()\n",
    "            ]\n",
    "            self.labels = labels_df[\"label\"].tolist()\n",
    "\n",
    "            if self.label_encoder is None:\n",
    "                self.label_encoder = LabelEncoder()\n",
    "                self.label_encoder.fit(\n",
    "                    [\"Luminal A\", \"Luminal B\", \"HER2(+)\", \"Triple negative\"]\n",
    "                )\n",
    "            self.encoded_labels = self.label_encoder.transform(self.labels)\n",
    "\n",
    "    def _clean_sample_idx(self, sample_idx: str) -> str:\n",
    "        \"\"\"Clean sample index by removing prefix and suffix.\"\"\"\n",
    "        sample_idx = str(sample_idx)\n",
    "        if sample_idx.startswith(\"img_\"):\n",
    "            sample_idx = sample_idx[4:]\n",
    "        if sample_idx.endswith(\".png\"):\n",
    "            sample_idx = sample_idx[:-4]\n",
    "        return sample_idx\n",
    "\n",
    "    def _get_test_samples(self) -> List[str]:\n",
    "        \"\"\"Get list of sample indices from test directory.\"\"\"\n",
    "        samples = []\n",
    "        for f in sorted(self.data_dir.glob(\"img_*.png\")):\n",
    "            sample_idx = self._clean_sample_idx(f.stem)\n",
    "            samples.append(sample_idx)\n",
    "        return samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _load_image_and_mask(\n",
    "        self, sample_idx: str\n",
    "    ) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n",
    "        \"\"\"Load image and optionally its mask.\"\"\"\n",
    "        img_path = self.data_dir / f\"img_{sample_idx}.png\"\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        mask = None\n",
    "        if self.use_mask:\n",
    "            mask_path = self.data_dir / f\"mask_{sample_idx}.png\"\n",
    "            if mask_path.exists():\n",
    "                mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def _crop_to_tissue_bbox(self, img: np.ndarray, mask: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Crop image to bounding box of tissue region.\"\"\"\n",
    "        # Find bounding box of tissue\n",
    "        rows = np.any(mask > 0, axis=1)\n",
    "        cols = np.any(mask > 0, axis=0)\n",
    "\n",
    "        if not rows.any() or not cols.any():\n",
    "            return img  # No tissue found, return original\n",
    "\n",
    "        y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "        x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "        # Add small padding\n",
    "        padding = 10\n",
    "        y_min = max(0, y_min - padding)\n",
    "        y_max = min(img.shape[0], y_max + padding)\n",
    "        x_min = max(0, x_min - padding)\n",
    "        x_max = min(img.shape[1], x_max + padding)\n",
    "\n",
    "        return img[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    def _apply_stain_normalization(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply stain normalization to image.\"\"\"\n",
    "        if self.use_stain_norm and self.stain_normalizer is not None:\n",
    "            try:\n",
    "                return self.stain_normalizer.normalize(img)\n",
    "            except Exception:\n",
    "                pass  # Skip normalization if it fails\n",
    "        return img\n",
    "\n",
    "    def _load_and_preprocess(self, sample_idx: str) -> np.ndarray:\n",
    "        \"\"\"Load and preprocess full image with optional tissue cropping.\"\"\"\n",
    "        img, mask = self._load_image_and_mask(sample_idx)\n",
    "\n",
    "        # Crop to tissue region if mask is available\n",
    "        if mask is not None:\n",
    "            img = self._crop_to_tissue_bbox(img, mask)\n",
    "\n",
    "        # Stain normalization\n",
    "        if self.use_stain_norm:\n",
    "            img = self._apply_stain_normalization(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def _load_patches(self, sample_idx: str) -> List[np.ndarray]:\n",
    "        \"\"\"Load image as patches using TissueExtractor.\"\"\"\n",
    "        img, mask = self._load_image_and_mask(sample_idx)\n",
    "\n",
    "        if mask is None:\n",
    "            # If no mask, create a simple one (all tissue)\n",
    "            mask = np.ones(img.shape[:2], dtype=np.uint8) * 255\n",
    "\n",
    "        # Extract patches using TissueExtractor\n",
    "        patches, _ = self.tissue_extractor.get_valid_patches(\n",
    "            img=img,\n",
    "            mask=mask,\n",
    "            num_patches=self.num_patches,\n",
    "            strategy=self.patch_strategy,\n",
    "            stride=self.patch_size // 2 if self.patch_strategy == \"grid\" else None,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        # Handle case where fewer patches are found than requested\n",
    "        if len(patches) == 0:\n",
    "            # Fallback: extract center crop\n",
    "            h, w = img.shape[:2]\n",
    "            cy, cx = h // 2, w // 2\n",
    "            half = self.patch_size // 2\n",
    "            y1 = max(0, cy - half)\n",
    "            x1 = max(0, cx - half)\n",
    "            y2 = min(h, y1 + self.patch_size)\n",
    "            x2 = min(w, x1 + self.patch_size)\n",
    "            fallback_patch = img[y1:y2, x1:x2]\n",
    "            fallback_patch = cv2.resize(\n",
    "                fallback_patch, (self.patch_size, self.patch_size)\n",
    "            )\n",
    "            patches = [fallback_patch] * self.num_patches\n",
    "\n",
    "        elif len(patches) < self.num_patches:\n",
    "            # Duplicate existing patches to reach num_patches\n",
    "            while len(patches) < self.num_patches:\n",
    "                patches.append(patches[len(patches) % len(patches)])\n",
    "\n",
    "        # Apply stain normalization to each patch\n",
    "        normalized_patches = []\n",
    "        for patch in patches:\n",
    "            patch = self._apply_stain_normalization(patch)\n",
    "            normalized_patches.append(patch)\n",
    "\n",
    "        return normalized_patches\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, ...]:\n",
    "        sample_idx = self.samples[idx]\n",
    "\n",
    "        if self.use_patches:\n",
    "            patches = self._load_patches(sample_idx)\n",
    "\n",
    "            # Transform each patch\n",
    "            transformed_patches = []\n",
    "            for patch in patches:\n",
    "                patch_pil = Image.fromarray(patch)\n",
    "                if self.transform:\n",
    "                    patch_tensor = self.transform(patch_pil)\n",
    "                else:\n",
    "                    patch_tensor = transforms.ToTensor()(patch_pil)\n",
    "                transformed_patches.append(patch_tensor)\n",
    "\n",
    "            # Stack patches [num_patches, C, H, W]\n",
    "            img_tensor = torch.stack(transformed_patches)\n",
    "        else:\n",
    "            img = self._load_and_preprocess(sample_idx)\n",
    "            img_pil = Image.fromarray(img)\n",
    "\n",
    "            if self.transform:\n",
    "                img_tensor = self.transform(img_pil)\n",
    "            else:\n",
    "                img_tensor = transforms.ToTensor()(img_pil)\n",
    "\n",
    "        if self.is_test:\n",
    "            return img_tensor, sample_idx\n",
    "        else:\n",
    "            label = self.encoded_labels[idx]\n",
    "            return img_tensor, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Custom data module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathologyDataModule(L.LightningDataModule):\n",
    "    \"\"\"Lightning DataModule for histopathology image classification.\n",
    "\n",
    "    Args:\n",
    "        train_data_dir: Directory containing training images and masks.\n",
    "        test_data_dir: Directory containing test images and masks.\n",
    "        train_labels_path: Path to CSV file with training labels.\n",
    "        batch_size: Batch size for dataloaders.\n",
    "        num_workers: Number of workers for dataloaders.\n",
    "        img_size: Target image size (used when not using patches).\n",
    "        use_mask: Whether to use masks for tissue extraction.\n",
    "        use_patches: Whether to use patch-based loading.\n",
    "        patch_size: Size of patches to extract.\n",
    "        num_patches: Number of patches per image.\n",
    "        min_tissue_ratio: Minimum tissue ratio for valid patches.\n",
    "        use_stain_norm: Whether to apply stain normalization.\n",
    "        val_split: Fraction of training data to use for validation.\n",
    "        random_seed: Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data_dir: str = Config.TRAIN_DATA_DIR,\n",
    "        test_data_dir: str = Config.TEST_DATA_DIR,\n",
    "        train_labels_path: str = Config.TRAIN_LABELS_PATH,\n",
    "        batch_size: int = Config.BATCH_SIZE,\n",
    "        num_workers: int = Config.NUM_WORKERS,\n",
    "        img_size: int = Config.IMG_SIZE,\n",
    "        use_mask: bool = Config.USE_MASK,\n",
    "        use_patches: bool = Config.USE_PATCHES,\n",
    "        patch_size: int = Config.PATCH_SIZE,\n",
    "        num_patches: int = Config.NUM_PATCHES,\n",
    "        min_tissue_ratio: float = Config.MIN_TISSUE_AREA,\n",
    "        use_stain_norm: bool = Config.USE_STAIN_NORMALIZATION,\n",
    "        val_split: float = Config.VAL_SPLIT,\n",
    "        random_seed: int = Config.RANDOM_SEED,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.train_data_dir = train_data_dir\n",
    "        self.test_data_dir = test_data_dir\n",
    "        self.train_labels_path = train_labels_path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.img_size = img_size\n",
    "        self.use_mask = use_mask\n",
    "        self.use_patches = use_patches\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "        self.min_tissue_ratio = min_tissue_ratio\n",
    "        self.use_stain_norm = use_stain_norm\n",
    "        self.val_split = val_split\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        # Initialize label encoder\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_encoder.fit(Config.CLASSES)\n",
    "\n",
    "        # Will be set in setup()\n",
    "        self.train_df = None\n",
    "        self.val_df = None\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "    def _get_train_transforms(self) -> transforms.Compose:\n",
    "        \"\"\"Get augmentation transforms for training.\"\"\"\n",
    "        target_size = self.patch_size if self.use_patches else self.img_size\n",
    "        return transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((target_size, target_size)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=90),\n",
    "                transforms.ColorJitter(\n",
    "                    brightness=0.2,\n",
    "                    contrast=0.2,\n",
    "                    saturation=0.1,\n",
    "                    hue=0.05,\n",
    "                ),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _get_val_transforms(self) -> transforms.Compose:\n",
    "        \"\"\"Get transforms for validation/test (no augmentation).\"\"\"\n",
    "        target_size = self.patch_size if self.use_patches else self.img_size\n",
    "        return transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((target_size, target_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"Setup datasets for each stage.\"\"\"\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            # Load and split training data\n",
    "            full_df = pd.read_csv(self.train_labels_path)\n",
    "\n",
    "            # Stratified split\n",
    "            from sklearn.model_selection import train_test_split\n",
    "\n",
    "            self.train_df, self.val_df = train_test_split(\n",
    "                full_df,\n",
    "                test_size=self.val_split,\n",
    "                stratify=full_df[\"label\"],\n",
    "                random_state=self.random_seed,\n",
    "            )\n",
    "\n",
    "            # Training dataset: random strategy with half overlap\n",
    "            self.train_dataset = PathologyDataset(\n",
    "                data_dir=self.train_data_dir,\n",
    "                labels_df=self.train_df,\n",
    "                transform=self._get_train_transforms(),\n",
    "                use_mask=self.use_mask,\n",
    "                use_patches=self.use_patches,\n",
    "                patch_size=self.patch_size,\n",
    "                num_patches=self.num_patches,\n",
    "                patch_strategy=\"random\",  # Random for training\n",
    "                min_tissue_ratio=self.min_tissue_ratio,\n",
    "                use_stain_norm=self.use_stain_norm,\n",
    "                is_test=False,\n",
    "                label_encoder=self.label_encoder,\n",
    "            )\n",
    "\n",
    "            # Validation dataset: grid strategy with no overlap\n",
    "            self.val_dataset = PathologyDataset(\n",
    "                data_dir=self.train_data_dir,\n",
    "                labels_df=self.val_df,\n",
    "                transform=self._get_val_transforms(),\n",
    "                use_mask=self.use_mask,\n",
    "                use_patches=self.use_patches,\n",
    "                patch_size=self.patch_size,\n",
    "                num_patches=self.num_patches,\n",
    "                patch_strategy=\"grid\",  # Grid for validation\n",
    "                min_tissue_ratio=self.min_tissue_ratio,\n",
    "                use_stain_norm=self.use_stain_norm,\n",
    "                is_test=False,\n",
    "                label_encoder=self.label_encoder,\n",
    "            )\n",
    "\n",
    "        if stage == \"test\" or stage == \"predict\" or stage is None:\n",
    "            # Test dataset: grid strategy with no overlap\n",
    "            self.test_dataset = PathologyDataset(\n",
    "                data_dir=self.test_data_dir,\n",
    "                labels_df=None,\n",
    "                transform=self._get_val_transforms(),\n",
    "                use_mask=self.use_mask,\n",
    "                use_patches=self.use_patches,\n",
    "                patch_size=self.patch_size,\n",
    "                num_patches=self.num_patches,\n",
    "                patch_strategy=\"grid\",\n",
    "                min_tissue_ratio=self.min_tissue_ratio,\n",
    "                use_stain_norm=self.use_stain_norm,\n",
    "                is_test=True,\n",
    "                label_encoder=self.label_encoder,\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self) -> DataLoader:\n",
    "        return self.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Define neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathologyModel(L.LightningModule):\n",
    "    \"\"\"Lightning Module for histopathology image classification using timm ResNet.\n",
    "\n",
    "    Args:\n",
    "        model_name: Name of the timm model to use (e.g., 'resnet50', 'resnet34').\n",
    "        num_classes: Number of output classes.\n",
    "        pretrained: Whether to use pretrained weights.\n",
    "        learning_rate: Learning rate for optimizer.\n",
    "        weight_decay: Weight decay for optimizer.\n",
    "        use_patches: Whether input is patch-based [B, num_patches, C, H, W].\n",
    "        patch_aggregation: How to aggregate patch features ('mean', 'max', 'attention').\n",
    "        dropout_rate: Dropout rate before final classifier.\n",
    "        label_smoothing: Label smoothing factor for cross-entropy loss.\n",
    "        class_weights: Optional tensor of class weights for imbalanced data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"resnet50\",\n",
    "        num_classes: int = Config.NUM_CLASSES,\n",
    "        pretrained: bool = True,\n",
    "        learning_rate: float = Config.LEARNING_RATE,\n",
    "        weight_decay: float = Config.WEIGHT_DECAY,\n",
    "        use_patches: bool = Config.USE_PATCHES,\n",
    "        patch_aggregation: str = \"mean\",\n",
    "        dropout_rate: float = 0.3,\n",
    "        label_smoothing: float = 0.1,\n",
    "        class_weights: Optional[torch.Tensor] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"class_weights\"])\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.use_patches = use_patches\n",
    "        self.patch_aggregation = patch_aggregation\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "        # Build backbone\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,  # Remove classifier head, we'll add our own\n",
    "        )\n",
    "\n",
    "        # Get feature dimension from backbone\n",
    "        self.feature_dim = self.backbone.num_features\n",
    "\n",
    "        # Attention module for patch aggregation (optional)\n",
    "        if patch_aggregation == \"attention\":\n",
    "            self.attention = nn.Sequential(\n",
    "                nn.Linear(self.feature_dim, 128),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(128, 1),\n",
    "            )\n",
    "        else:\n",
    "            self.attention = None\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(self.feature_dim, num_classes),\n",
    "        )\n",
    "\n",
    "        # Loss function\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=class_weights,\n",
    "            label_smoothing=label_smoothing,\n",
    "        )\n",
    "\n",
    "        # Metrics\n",
    "        self._setup_metrics()\n",
    "\n",
    "    def _setup_metrics(self):\n",
    "        \"\"\"Initialize metrics for training, validation, and test.\"\"\"\n",
    "        # Accuracy\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "        # F1 Score (macro averaged)\n",
    "        self.train_f1 = F1Score(\n",
    "            task=\"multiclass\", num_classes=self.num_classes, average=\"macro\"\n",
    "        )\n",
    "        self.val_f1 = F1Score(\n",
    "            task=\"multiclass\", num_classes=self.num_classes, average=\"macro\"\n",
    "        )\n",
    "        self.test_f1 = F1Score(\n",
    "            task=\"multiclass\", num_classes=self.num_classes, average=\"macro\"\n",
    "        )\n",
    "\n",
    "        # AUROC (one-vs-rest)\n",
    "        self.val_auroc = AUROC(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_auroc = AUROC(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "        # Confusion matrix for test\n",
    "        self.test_confmat = ConfusionMatrix(\n",
    "            task=\"multiclass\", num_classes=self.num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor. Shape depends on use_patches:\n",
    "               - If use_patches=False: [B, C, H, W]\n",
    "               - If use_patches=True: [B, num_patches, C, H, W]\n",
    "\n",
    "        Returns:\n",
    "            Logits of shape [B, num_classes]\n",
    "        \"\"\"\n",
    "        if self.use_patches and x.dim() == 5:\n",
    "            # Patch-based input: [B, num_patches, C, H, W]\n",
    "            batch_size, num_patches, c, h, w = x.shape\n",
    "\n",
    "            # Reshape to process all patches at once\n",
    "            x = x.view(batch_size * num_patches, c, h, w)\n",
    "\n",
    "            # Extract features for all patches\n",
    "            features = self.backbone(x)  # [B * num_patches, feature_dim]\n",
    "\n",
    "            # Reshape back to [B, num_patches, feature_dim]\n",
    "            features = features.view(batch_size, num_patches, -1)\n",
    "\n",
    "            # Aggregate patch features\n",
    "            features = self._aggregate_patches(features)  # [B, feature_dim]\n",
    "        else:\n",
    "            # Standard input: [B, C, H, W]\n",
    "            features = self.backbone(x)  # [B, feature_dim]\n",
    "\n",
    "        # Classification\n",
    "        logits = self.classifier(features)  # [B, num_classes]\n",
    "        return logits\n",
    "\n",
    "    def _aggregate_patches(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Aggregate features from multiple patches.\n",
    "\n",
    "        Args:\n",
    "            features: Patch features of shape [B, num_patches, feature_dim]\n",
    "\n",
    "        Returns:\n",
    "            Aggregated features of shape [B, feature_dim]\n",
    "        \"\"\"\n",
    "        if self.patch_aggregation == \"mean\":\n",
    "            return features.mean(dim=1)\n",
    "\n",
    "        elif self.patch_aggregation == \"max\":\n",
    "            return features.max(dim=1)[0]\n",
    "\n",
    "        elif self.patch_aggregation == \"attention\":\n",
    "            # Attention-based aggregation (MIL-style)\n",
    "            # attention_weights: [B, num_patches, 1]\n",
    "            attention_scores = self.attention(features)\n",
    "            attention_weights = F.softmax(attention_scores, dim=1)\n",
    "\n",
    "            # Weighted sum: [B, feature_dim]\n",
    "            aggregated = (attention_weights * features).sum(dim=1)\n",
    "            return aggregated\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown aggregation method: {self.patch_aggregation}\")\n",
    "\n",
    "    def training_step(self, batch: tuple, batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        # Get predictions\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Update metrics\n",
    "        self.train_acc(preds, y)\n",
    "        self.train_f1(preds, y)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"train/loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\n",
    "            \"train/acc\", self.train_acc, on_step=False, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\"train/f1\", self.train_f1, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: tuple, batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        # Get predictions and probabilities\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        # Update metrics\n",
    "        self.val_acc(preds, y)\n",
    "        self.val_f1(preds, y)\n",
    "        self.val_auroc(probs, y)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"val/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/acc\", self.val_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/f1\", self.val_f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/auroc\", self.val_auroc, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch: tuple, batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        # Get predictions and probabilities\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        # Update metrics\n",
    "        self.test_acc(preds, y)\n",
    "        self.test_f1(preds, y)\n",
    "        self.test_auroc(probs, y)\n",
    "        self.test_confmat(preds, y)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"test/loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"test/acc\", self.test_acc, on_step=False, on_epoch=True)\n",
    "        self.log(\"test/f1\", self.test_f1, on_step=False, on_epoch=True)\n",
    "        self.log(\"test/auroc\", self.test_auroc, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch: tuple, batch_idx: int) -> Dict[str, Any]:\n",
    "        \"\"\"Prediction step for inference.\"\"\"\n",
    "        x, sample_ids = batch\n",
    "        logits = self(x)\n",
    "\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        return {\n",
    "            \"sample_ids\": sample_ids,\n",
    "            \"predictions\": preds,\n",
    "            \"probabilities\": probs,\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self) -> Dict[str, Any]:\n",
    "        \"\"\"Configure optimizer and learning rate scheduler.\"\"\"\n",
    "        # Use different learning rates for backbone and classifier\n",
    "        backbone_params = list(self.backbone.parameters())\n",
    "        classifier_params = list(self.classifier.parameters())\n",
    "\n",
    "        if self.attention is not None:\n",
    "            classifier_params += list(self.attention.parameters())\n",
    "\n",
    "        param_groups = [\n",
    "            {\n",
    "                \"params\": backbone_params,\n",
    "                \"lr\": self.learning_rate * 0.1,\n",
    "            },  # Lower LR for pretrained backbone\n",
    "            {\"params\": classifier_params, \"lr\": self.learning_rate},\n",
    "        ]\n",
    "\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            param_groups,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "        # Cosine annealing scheduler with warm restarts\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0=10,  # Restart every 10 epochs\n",
    "            T_mult=2,  # Double the period after each restart\n",
    "            eta_min=1e-7,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        \"\"\"Log confusion matrix at end of test epoch.\"\"\"\n",
    "        confmat = self.test_confmat.compute()\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confmat.cpu().numpy())\n",
    "\n",
    "        # Per-class accuracy\n",
    "        per_class_acc = confmat.diag() / confmat.sum(dim=1)\n",
    "        for i, class_name in enumerate(Config.CLASSES):\n",
    "            print(f\"  {class_name}: {per_class_acc[i]:.4f}\")\n",
    "\n",
    "\n",
    "class PathologyModelWithMixup(PathologyModel):\n",
    "    \"\"\"Extended model with Mixup/CutMix augmentation for improved generalization.\n",
    "\n",
    "    Args:\n",
    "        mixup_alpha: Alpha parameter for mixup. Set to 0 to disable.\n",
    "        cutmix_alpha: Alpha parameter for cutmix. Set to 0 to disable.\n",
    "        mixup_prob: Probability of applying mixup/cutmix.\n",
    "        **kwargs: Arguments passed to PathologyModel.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mixup_alpha: float = 0.4,\n",
    "        cutmix_alpha: float = 1.0,\n",
    "        mixup_prob: float = 0.5,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.cutmix_alpha = cutmix_alpha\n",
    "        self.mixup_prob = mixup_prob\n",
    "\n",
    "    def _mixup_data(self, x: torch.Tensor, y: torch.Tensor) -> tuple:\n",
    "        \"\"\"Apply mixup augmentation.\"\"\"\n",
    "        if self.mixup_alpha > 0:\n",
    "            lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "        else:\n",
    "            lam = 1.0\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        index = torch.randperm(batch_size, device=x.device)\n",
    "\n",
    "        mixed_x = lam * x + (1 - lam) * x[index]\n",
    "        y_a, y_b = y, y[index]\n",
    "\n",
    "        return mixed_x, y_a, y_b, lam\n",
    "\n",
    "    def _mixup_criterion(\n",
    "        self, logits: torch.Tensor, y_a: torch.Tensor, y_b: torch.Tensor, lam: float\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Compute mixup loss.\"\"\"\n",
    "        return lam * self.criterion(logits, y_a) + (1 - lam) * self.criterion(\n",
    "            logits, y_b\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch: tuple, batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "\n",
    "        # Apply mixup with probability\n",
    "        if self.training and np.random.random() < self.mixup_prob:\n",
    "            x, y_a, y_b, lam = self._mixup_data(x, y)\n",
    "            logits = self(x)\n",
    "            loss = self._mixup_criterion(logits, y_a, y_b, lam)\n",
    "\n",
    "            # For metrics, use the dominant class\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            target = y_a if lam > 0.5 else y_b\n",
    "        else:\n",
    "            logits = self(x)\n",
    "            loss = self.criterion(logits, y)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            target = y\n",
    "\n",
    "        # Update metrics\n",
    "        self.train_acc(preds, target)\n",
    "        self.train_f1(preds, target)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"train/loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\n",
    "            \"train/acc\", self.train_acc, on_step=False, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\"train/f1\", self.train_f1, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Train logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Initialize\n",
    "datamodule = PathologyDataModule()\n",
    "model = PathologyModel(\n",
    "    model_name=\"resnet50\",  # or resnet34, resnet101, etc.\n",
    "    use_patches=True,\n",
    "    patch_aggregation=\"attention\",\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=Config.MAX_EPOCHS,\n",
    "    accelerator=\"auto\",\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor=\"val/f1\", mode=\"max\"),\n",
    "        EarlyStopping(monitor=\"val/loss\", patience=10),\n",
    "    ],\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=0.5,\n",
    "    precision=\"16-mixed\",\n",
    "    devices=2,\n",
    ")\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Inference logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on test set\n",
    "# 1. Load the best model from the checkpoint\n",
    "best_checkpoint = (\n",
    "    \"/kaggle/working/lightning_logs/version_2/checkpoints/epoch=45-step=1610.ckpt\"\n",
    ")\n",
    "\n",
    "print(f\"Loading model from: {best_checkpoint}\")\n",
    "best_model = PathologyModel.load_from_checkpoint(best_checkpoint)\n",
    "\n",
    "datamodule = PathologyDataModule()\n",
    "datamodule.setup(stage=\"test\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    precision=\"16-mixed\",\n",
    ")\n",
    "\n",
    "# 2. Run prediction using the Trainer\n",
    "print(\"Generating predictions...\")\n",
    "predictions = trainer.predict(best_model, datamodule=datamodule)\n",
    "\n",
    "# 3. Process the results\n",
    "sample_ids = []\n",
    "pred_labels_encoded = []\n",
    "\n",
    "for batch in predictions:\n",
    "    sample_ids.extend(batch[\"sample_ids\"])\n",
    "    pred_labels_encoded.extend(batch[\"predictions\"].cpu().numpy().tolist())\n",
    "\n",
    "# 4. Decode integer labels back to string labels\n",
    "decoded_labels = datamodule.label_encoder.inverse_transform(pred_labels_encoded)\n",
    "\n",
    "# 5. Format sample_ids back to filenames (e.g., \"1004\" -> \"img_1004.png\")\n",
    "# We assume sample_ids contains the raw ID strings (e.g., \"1004\", \"1005\")\n",
    "formatted_sample_ids = [f\"img_{sid}.png\" for sid in sample_ids]\n",
    "\n",
    "# 6. Create DataFrame\n",
    "submission_df = pd.DataFrame(\n",
    "    {\"sample_index\": formatted_sample_ids, \"label\": decoded_labels}\n",
    ")\n",
    "\n",
    "# Optional: Sort by sample_index for a cleaner look\n",
    "submission_df = submission_df.sort_values(\"sample_index\").reset_index(drop=True)\n",
    "\n",
    "# 7. Save to CSV\n",
    "output_csv_path = \"submission.csv\"\n",
    "submission_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"Submission saved to: {output_csv_path}\")\n",
    "print(f\"Total samples predicted: {len(submission_df)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Preview the first few rows\n",
    "print(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
