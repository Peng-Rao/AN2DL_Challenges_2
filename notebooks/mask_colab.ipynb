{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1rh_21CJliIkuahqqaWETH8Zf06qEA7eG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir temp\n",
    "!mkdir data\n",
    "!unzip -q data.zip -d temp\n",
    "!mv temp/data/* data/\n",
    "!rm -rf temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import lightning.pytorch as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from lightning.pytorch import LightningDataModule, LightningModule, Trainer\n",
    "from lightning.pytorch.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Configuration\n",
    "# ============================================================================\n",
    "class Config:\n",
    "    # Data paths\n",
    "    DATA_DIR = \"./data\"\n",
    "    TRAIN_DATA_DIR = \"./data/train_data\"\n",
    "    TEST_DATA_DIR = \"./data/test_data\"\n",
    "    TRAIN_LABELS_PATH = \"./data/train_labels_cleaned.csv\"\n",
    "    OUTPUT_PATH = \"./predictions.csv\"\n",
    "\n",
    "    # Class labels\n",
    "    CLASSES = [\"Luminal A\", \"Luminal B\", \"HER2(+)\", \"Triple negative\"]\n",
    "    NUM_CLASSES = 4\n",
    "\n",
    "    # Image settings\n",
    "    IMG_SIZE = 512  # Larger size for histopathology\n",
    "    USE_MASK = True\n",
    "\n",
    "    # Mask mode: \"multiply\" (apply mask), \"channel\" (4th channel), \"attention\" (learned attention)\n",
    "    MASK_MODE = \"channel\"  # Use mask as 4th input channel\n",
    "    IN_CHANNELS = 4  # 3 (RGB) + 1 (mask) when MASK_MODE=\"channel\", else 3\n",
    "\n",
    "    # Tissue detection settings\n",
    "    TISSUE_THRESHOLD = 0.8  # Threshold for tissue detection (lower = more sensitive)\n",
    "    MIN_TISSUE_AREA = 0.05  # Minimum tissue area ratio\n",
    "    PADDING = 50  # Padding around tissue bounding box\n",
    "\n",
    "    # Patch-based settings (for very large images)\n",
    "    USE_PATCHES = False  # Set to False for simpler 4-channel approach\n",
    "    PATCH_SIZE = 512\n",
    "    NUM_PATCHES = 8  # Number of patches to sample per image\n",
    "\n",
    "    # Stain normalization\n",
    "    USE_STAIN_NORMALIZATION = True\n",
    "\n",
    "    # Training settings\n",
    "    BATCH_SIZE = 4\n",
    "    NUM_WORKERS = 2\n",
    "    MAX_EPOCHS = 100\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "\n",
    "    # Model settings\n",
    "    MODEL_NAME = \"efficientnet_b3\"\n",
    "    PRETRAINED = True\n",
    "\n",
    "    # Validation split\n",
    "    VAL_SPLIT = 0.2\n",
    "    RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Stain Normalization (Macenko method simplified)\n",
    "# ============================================================================\n",
    "class StainNormalizer:\n",
    "    \"\"\"Simple stain normalization for H&E images.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Reference stain vectors (standard H&E)\n",
    "        self.target_means = np.array([148.60, 41.56, 105.97])  # LAB color space\n",
    "        self.target_stds = np.array([41.56, 9.01, 6.67])\n",
    "\n",
    "    def normalize(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalize stain colors using LAB color space.\"\"\"\n",
    "        if img.dtype != np.uint8:\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "\n",
    "        # Convert to LAB\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB).astype(np.float32)\n",
    "\n",
    "        # Normalize each channel\n",
    "        for i in range(3):\n",
    "            channel = lab[:, :, i]\n",
    "            channel_mean = channel.mean()\n",
    "            channel_std = channel.std() + 1e-6\n",
    "\n",
    "            # Normalize to target distribution\n",
    "            lab[:, :, i] = ((channel - channel_mean) / channel_std) * self.target_stds[\n",
    "                i\n",
    "            ] + self.target_means[i]\n",
    "\n",
    "        # Clip and convert back\n",
    "        lab = np.clip(lab, 0, 255).astype(np.uint8)\n",
    "        normalized = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "        return normalized\n",
    "\n",
    "\n",
    "class ReinhardNormalizer:\n",
    "    \"\"\"Reinhard stain normalization.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Target statistics (can be computed from a reference image)\n",
    "        self.target_means = None\n",
    "        self.target_stds = None\n",
    "        self._set_default_target()\n",
    "\n",
    "    def _set_default_target(self):\n",
    "        \"\"\"Set default target statistics for H&E.\"\"\"\n",
    "        self.target_means = np.array([180.0, 135.0, 165.0])\n",
    "        self.target_stds = np.array([25.0, 15.0, 20.0])\n",
    "\n",
    "    def fit(self, target_img: np.ndarray):\n",
    "        \"\"\"Fit normalizer to a target image.\"\"\"\n",
    "        lab = cv2.cvtColor(target_img, cv2.COLOR_RGB2LAB).astype(np.float32)\n",
    "        self.target_means = np.array([lab[:, :, i].mean() for i in range(3)])\n",
    "        self.target_stds = np.array([lab[:, :, i].std() for i in range(3)])\n",
    "\n",
    "    def normalize(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalize image to target statistics.\"\"\"\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB).astype(np.float32)\n",
    "\n",
    "        for i in range(3):\n",
    "            src_mean = lab[:, :, i].mean()\n",
    "            src_std = lab[:, :, i].std() + 1e-6\n",
    "            lab[:, :, i] = ((lab[:, :, i] - src_mean) / src_std) * self.target_stds[\n",
    "                i\n",
    "            ] + self.target_means[i]\n",
    "\n",
    "        lab = np.clip(lab, 0, 255).astype(np.uint8)\n",
    "        return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Tissue Detection and Preprocessing\n",
    "# ============================================================================\n",
    "class TissueDetector:\n",
    "    \"\"\"Detect and extract tissue regions from histopathology images.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, threshold: float = 0.8, min_area_ratio: float = 0.05, padding: int = 50\n",
    "    ):\n",
    "        self.threshold = threshold\n",
    "        self.min_area_ratio = min_area_ratio\n",
    "        self.padding = padding\n",
    "\n",
    "    def detect_tissue_mask(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Create binary mask of tissue regions.\"\"\"\n",
    "        # Convert to grayscale\n",
    "        if len(img.shape) == 3:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = img\n",
    "\n",
    "        # Tissue is darker than background (which is usually white/light gray)\n",
    "        # Use Otsu's thresholding\n",
    "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Alternative: threshold based on intensity\n",
    "        # Background is typically > 200 in grayscale\n",
    "        intensity_mask = gray < 220\n",
    "\n",
    "        # Combine with saturation (tissue has color, background doesn't)\n",
    "        if len(img.shape) == 3:\n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "            saturation = hsv[:, :, 1]\n",
    "            saturation_mask = saturation > 10\n",
    "            tissue_mask = intensity_mask & saturation_mask\n",
    "        else:\n",
    "            tissue_mask = intensity_mask\n",
    "\n",
    "        # Clean up mask\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        tissue_mask = cv2.morphologyEx(\n",
    "            tissue_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel\n",
    "        )\n",
    "        tissue_mask = cv2.morphologyEx(tissue_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Fill holes\n",
    "        tissue_mask = ndimage.binary_fill_holes(tissue_mask).astype(np.uint8)\n",
    "\n",
    "        return tissue_mask * 255\n",
    "\n",
    "    def get_tissue_bbox(self, mask: np.ndarray) -> Tuple[int, int, int, int]:\n",
    "        \"\"\"Get bounding box of tissue region.\"\"\"\n",
    "        coords = np.where(mask > 0)\n",
    "        if len(coords[0]) == 0:\n",
    "            return 0, 0, mask.shape[1], mask.shape[0]\n",
    "\n",
    "        y_min, y_max = coords[0].min(), coords[0].max()\n",
    "        x_min, x_max = coords[1].min(), coords[1].max()\n",
    "\n",
    "        # Add padding\n",
    "        h, w = mask.shape[:2]\n",
    "        y_min = max(0, y_min - self.padding)\n",
    "        y_max = min(h, y_max + self.padding)\n",
    "        x_min = max(0, x_min - self.padding)\n",
    "        x_max = min(w, x_max + self.padding)\n",
    "\n",
    "        return x_min, y_min, x_max, y_max\n",
    "\n",
    "    def crop_tissue(\n",
    "        self, img: np.ndarray, mask: Optional[np.ndarray] = None\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Crop image to tissue region.\"\"\"\n",
    "        if mask is None:\n",
    "            mask = self.detect_tissue_mask(img)\n",
    "\n",
    "        x_min, y_min, x_max, y_max = self.get_tissue_bbox(mask)\n",
    "        cropped = img[y_min:y_max, x_min:x_max]\n",
    "\n",
    "        # Ensure minimum size\n",
    "        if cropped.shape[0] < 100 or cropped.shape[1] < 100:\n",
    "            return img  # Return original if crop is too small\n",
    "\n",
    "        return cropped\n",
    "\n",
    "    def get_tissue_patches(\n",
    "        self,\n",
    "        img: np.ndarray,\n",
    "        patch_size: int = 512,\n",
    "        num_patches: int = 8,\n",
    "        mask: Optional[np.ndarray] = None,\n",
    "    ) -> List[np.ndarray]:\n",
    "        \"\"\"Extract patches from tissue regions.\"\"\"\n",
    "        if mask is None:\n",
    "            mask = self.detect_tissue_mask(img)\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "        patches = []\n",
    "\n",
    "        # Find tissue coordinates\n",
    "        tissue_coords = np.where(mask > 0)\n",
    "        if len(tissue_coords[0]) == 0:\n",
    "            # No tissue found, return center crop\n",
    "            cy, cx = h // 2, w // 2\n",
    "            half = patch_size // 2\n",
    "            patch = img[\n",
    "                max(0, cy - half) : min(h, cy + half),\n",
    "                max(0, cx - half) : min(w, cx + half),\n",
    "            ]\n",
    "            patch = cv2.resize(patch, (patch_size, patch_size))\n",
    "            return [patch] * num_patches\n",
    "\n",
    "        # Sample random tissue locations\n",
    "        for _ in range(num_patches * 3):  # Oversample to ensure we get enough\n",
    "            if len(patches) >= num_patches:\n",
    "                break\n",
    "\n",
    "            # Random tissue point\n",
    "            idx = np.random.randint(len(tissue_coords[0]))\n",
    "            cy, cx = tissue_coords[0][idx], tissue_coords[1][idx]\n",
    "\n",
    "            # Extract patch\n",
    "            half = patch_size // 2\n",
    "            y1, y2 = max(0, cy - half), min(h, cy + half)\n",
    "            x1, x2 = max(0, cx - half), min(w, cx + half)\n",
    "\n",
    "            patch = img[y1:y2, x1:x2]\n",
    "            patch_mask = mask[y1:y2, x1:x2]\n",
    "\n",
    "            # Check tissue ratio in patch\n",
    "            tissue_ratio = patch_mask.sum() / (patch_mask.size * 255)\n",
    "            if tissue_ratio > 0.3:  # At least 30% tissue\n",
    "                if patch.shape[0] != patch_size or patch.shape[1] != patch_size:\n",
    "                    patch = cv2.resize(patch, (patch_size, patch_size))\n",
    "                patches.append(patch)\n",
    "\n",
    "        # If not enough patches, duplicate\n",
    "        while len(patches) < num_patches:\n",
    "            if len(patches) > 0:\n",
    "                patches.append(patches[np.random.randint(len(patches))])\n",
    "            else:\n",
    "                # Fallback: center crop\n",
    "                cy, cx = h // 2, w // 2\n",
    "                half = patch_size // 2\n",
    "                patch = img[\n",
    "                    max(0, cy - half) : min(h, cy + half),\n",
    "                    max(0, cx - half) : min(w, cx + half),\n",
    "                ]\n",
    "                patch = cv2.resize(patch, (patch_size, patch_size))\n",
    "                patches.append(patch)\n",
    "\n",
    "        return patches[:num_patches]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Dataset\n",
    "# ============================================================================\n",
    "class PathologyDataset(Dataset):\n",
    "    \"\"\"Dataset optimized for histopathology images.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        labels_df: Optional[pd.DataFrame] = None,\n",
    "        transform: Optional[transforms.Compose] = None,\n",
    "        img_size: int = 512,\n",
    "        use_mask: bool = True,\n",
    "        mask_mode: str = \"channel\",  # \"multiply\", \"channel\", or \"attention\"\n",
    "        use_patches: bool = False,\n",
    "        patch_size: int = 512,\n",
    "        num_patches: int = 8,\n",
    "        use_stain_norm: bool = True,\n",
    "        is_test: bool = False,\n",
    "        label_encoder: Optional[LabelEncoder] = None,\n",
    "    ):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size\n",
    "        self.use_mask = use_mask\n",
    "        self.mask_mode = mask_mode\n",
    "        self.use_patches = use_patches\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "        self.use_stain_norm = use_stain_norm\n",
    "        self.is_test = is_test\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "        # Initialize helpers\n",
    "        self.tissue_detector = TissueDetector()\n",
    "        self.stain_normalizer = ReinhardNormalizer() if use_stain_norm else None\n",
    "\n",
    "        if is_test:\n",
    "            self.samples = self._get_test_samples()\n",
    "            self.labels = None\n",
    "        else:\n",
    "            self.samples = [\n",
    "                self._clean_sample_idx(str(idx))\n",
    "                for idx in labels_df[\"sample_index\"].tolist()\n",
    "            ]\n",
    "            self.labels = labels_df[\"label\"].tolist()\n",
    "\n",
    "            if self.label_encoder is None:\n",
    "                self.label_encoder = LabelEncoder()\n",
    "                self.label_encoder.fit(Config.CLASSES)\n",
    "            self.encoded_labels = self.label_encoder.transform(self.labels)\n",
    "\n",
    "    def _clean_sample_idx(self, sample_idx: str) -> str:\n",
    "        \"\"\"Clean sample index.\"\"\"\n",
    "        sample_idx = str(sample_idx)\n",
    "        if sample_idx.startswith(\"img_\"):\n",
    "            sample_idx = sample_idx[4:]\n",
    "        if sample_idx.endswith(\".png\"):\n",
    "            sample_idx = sample_idx[:-4]\n",
    "        return sample_idx\n",
    "\n",
    "    def _get_test_samples(self) -> List[str]:\n",
    "        \"\"\"Get list of sample indices from test directory.\"\"\"\n",
    "        samples = []\n",
    "        for f in sorted(self.data_dir.glob(\"img_*.png\")):\n",
    "            sample_idx = self._clean_sample_idx(f.stem)\n",
    "            samples.append(sample_idx)\n",
    "        return samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _load_and_preprocess(\n",
    "        self, sample_idx: str\n",
    "    ) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n",
    "        \"\"\"Load and preprocess image with tissue detection. Returns (image, mask).\"\"\"\n",
    "        img_path = self.data_dir / f\"img_{sample_idx}.png\"\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        # Load mask\n",
    "        mask = None\n",
    "        if self.use_mask:\n",
    "            mask_path = self.data_dir / f\"mask_{sample_idx}.png\"\n",
    "            if mask_path.exists():\n",
    "                mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "            else:\n",
    "                # Auto-detect tissue if no mask provided\n",
    "                mask = self.tissue_detector.detect_tissue_mask(img)\n",
    "\n",
    "        # Crop to tissue region (crop both image and mask together)\n",
    "        if mask is not None:\n",
    "            x_min, y_min, x_max, y_max = self.tissue_detector.get_tissue_bbox(mask)\n",
    "            img = img[y_min:y_max, x_min:x_max]\n",
    "            mask = mask[y_min:y_max, x_min:x_max]\n",
    "\n",
    "        # Stain normalization (only on RGB)\n",
    "        if self.use_stain_norm and self.stain_normalizer is not None:\n",
    "            try:\n",
    "                img = self.stain_normalizer.normalize(img)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Resize both image and mask\n",
    "        img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "        if mask is not None:\n",
    "            mask = cv2.resize(mask, (self.img_size, self.img_size))\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def _load_patches(\n",
    "        self, sample_idx: str\n",
    "    ) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "        \"\"\"Load image as patches. Returns (image_patches, mask_patches).\"\"\"\n",
    "        img_path = self.data_dir / f\"img_{sample_idx}.png\"\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        # Load mask\n",
    "        mask = None\n",
    "        if self.use_mask:\n",
    "            mask_path = self.data_dir / f\"mask_{sample_idx}.png\"\n",
    "            if mask_path.exists():\n",
    "                mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "\n",
    "        # Get patch coordinates\n",
    "        h, w = img.shape[:2]\n",
    "        tissue_coords = (\n",
    "            np.where(mask > 0)\n",
    "            if mask is not None\n",
    "            else (np.array([h // 2]), np.array([w // 2]))\n",
    "        )\n",
    "\n",
    "        img_patches = []\n",
    "        mask_patches = []\n",
    "\n",
    "        for _ in range(self.num_patches * 3):\n",
    "            if len(img_patches) >= self.num_patches:\n",
    "                break\n",
    "\n",
    "            if len(tissue_coords[0]) > 0:\n",
    "                idx = np.random.randint(len(tissue_coords[0]))\n",
    "                cy, cx = tissue_coords[0][idx], tissue_coords[1][idx]\n",
    "            else:\n",
    "                cy, cx = h // 2, w // 2\n",
    "\n",
    "            half = self.patch_size // 2\n",
    "            y1, y2 = max(0, cy - half), min(h, cy + half)\n",
    "            x1, x2 = max(0, cx - half), min(w, cx + half)\n",
    "\n",
    "            img_patch = img[y1:y2, x1:x2]\n",
    "            mask_patch = (\n",
    "                mask[y1:y2, x1:x2]\n",
    "                if mask is not None\n",
    "                else np.ones((y2 - y1, x2 - x1), dtype=np.uint8) * 255\n",
    "            )\n",
    "\n",
    "            tissue_ratio = (\n",
    "                mask_patch.sum() / (mask_patch.size * 255) if mask is not None else 1.0\n",
    "            )\n",
    "            if tissue_ratio > 0.3:\n",
    "                img_patch = cv2.resize(img_patch, (self.patch_size, self.patch_size))\n",
    "                mask_patch = cv2.resize(mask_patch, (self.patch_size, self.patch_size))\n",
    "\n",
    "                if self.use_stain_norm and self.stain_normalizer:\n",
    "                    try:\n",
    "                        img_patch = self.stain_normalizer.normalize(img_patch)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                img_patches.append(img_patch)\n",
    "                mask_patches.append(mask_patch)\n",
    "\n",
    "        # Ensure we have enough patches\n",
    "        while len(img_patches) < self.num_patches:\n",
    "            if len(img_patches) > 0:\n",
    "                idx = np.random.randint(len(img_patches))\n",
    "                img_patches.append(img_patches[idx])\n",
    "                mask_patches.append(mask_patches[idx])\n",
    "            else:\n",
    "                # Fallback\n",
    "                img_patch = cv2.resize(img, (self.patch_size, self.patch_size))\n",
    "                mask_patch = cv2.resize(\n",
    "                    mask if mask is not None else np.ones_like(img[:, :, 0]) * 255,\n",
    "                    (self.patch_size, self.patch_size),\n",
    "                )\n",
    "                img_patches.append(img_patch)\n",
    "                mask_patches.append(mask_patch)\n",
    "\n",
    "        return img_patches[: self.num_patches], mask_patches[: self.num_patches]\n",
    "\n",
    "    def _apply_transform(\n",
    "        self, img: np.ndarray, mask: Optional[np.ndarray] = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Apply transforms and combine image with mask based on mask_mode.\"\"\"\n",
    "\n",
    "        # Convert to PIL for transforms\n",
    "        img_pil = Image.fromarray(img)\n",
    "\n",
    "        if self.mask_mode == \"channel\" and mask is not None:\n",
    "            # Apply transform to RGB image\n",
    "            if self.transform:\n",
    "                # We need to handle this carefully - transform RGB, then add mask channel\n",
    "                # For now, apply basic transforms manually to keep mask aligned\n",
    "                img_tensor = self.transform(img_pil)  # [3, H, W]\n",
    "            else:\n",
    "                img_tensor = transforms.ToTensor()(img_pil)\n",
    "\n",
    "            # Normalize mask to 0-1 and resize to match transformed image size\n",
    "            mask_normalized = mask.astype(np.float32) / 255.0\n",
    "            mask_tensor = torch.from_numpy(mask_normalized).unsqueeze(0)  # [1, H, W]\n",
    "\n",
    "            # Resize mask if needed\n",
    "            if mask_tensor.shape[1:] != img_tensor.shape[1:]:\n",
    "                mask_tensor = F.interpolate(\n",
    "                    mask_tensor.unsqueeze(0), size=img_tensor.shape[1:], mode=\"nearest\"\n",
    "                ).squeeze(0)\n",
    "\n",
    "            # Concatenate RGB + Mask -> 4 channels\n",
    "            combined = torch.cat([img_tensor, mask_tensor], dim=0)  # [4, H, W]\n",
    "            return combined\n",
    "\n",
    "        elif self.mask_mode == \"multiply\" and mask is not None:\n",
    "            # Apply mask by multiplication\n",
    "            mask_normalized = mask.astype(np.float32) / 255.0\n",
    "            mask_3d = np.stack([mask_normalized] * 3, axis=-1)\n",
    "            img_masked = (img * mask_3d).astype(np.uint8)\n",
    "            img_pil = Image.fromarray(img_masked)\n",
    "\n",
    "            if self.transform:\n",
    "                return self.transform(img_pil)\n",
    "            else:\n",
    "                return transforms.ToTensor()(img_pil)\n",
    "\n",
    "        else:\n",
    "            # No mask or attention mode\n",
    "            if self.transform:\n",
    "                return self.transform(img_pil)\n",
    "            else:\n",
    "                return transforms.ToTensor()(img_pil)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, ...]:\n",
    "        sample_idx = self.samples[idx]\n",
    "\n",
    "        if self.use_patches:\n",
    "            img_patches, mask_patches = self._load_patches(sample_idx)\n",
    "\n",
    "            transformed_patches = []\n",
    "            for img_patch, mask_patch in zip(img_patches, mask_patches):\n",
    "                patch_tensor = self._apply_transform(img_patch, mask_patch)\n",
    "                transformed_patches.append(patch_tensor)\n",
    "\n",
    "            img_tensor = torch.stack(transformed_patches)  # [num_patches, C, H, W]\n",
    "        else:\n",
    "            img, mask = self._load_and_preprocess(sample_idx)\n",
    "            img_tensor = self._apply_transform(img, mask)\n",
    "\n",
    "        if self.is_test:\n",
    "            return img_tensor, sample_idx\n",
    "        else:\n",
    "            label = self.encoded_labels[idx]\n",
    "            return img_tensor, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Data Module\n",
    "# ============================================================================\n",
    "class PathologyDataModule(LightningDataModule):\n",
    "    \"\"\"DataModule for pathology images.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config = Config()):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_encoder.fit(config.CLASSES)\n",
    "\n",
    "        # Transforms\n",
    "        self.train_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=90),\n",
    "                transforms.ColorJitter(\n",
    "                    brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05\n",
    "                ),\n",
    "                transforms.RandomAffine(\n",
    "                    degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)\n",
    "                ),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.val_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            labels_df = pd.read_csv(self.config.TRAIN_LABELS_PATH)\n",
    "\n",
    "            def clean_idx(idx):\n",
    "                idx = str(idx)\n",
    "                if idx.startswith(\"img_\"):\n",
    "                    idx = idx[4:]\n",
    "                if idx.endswith(\".png\"):\n",
    "                    idx = idx[:-4]\n",
    "                return idx\n",
    "\n",
    "            labels_df[\"sample_index\"] = labels_df[\"sample_index\"].apply(clean_idx)\n",
    "\n",
    "            train_df, val_df = train_test_split(\n",
    "                labels_df,\n",
    "                test_size=self.config.VAL_SPLIT,\n",
    "                stratify=labels_df[\"label\"],\n",
    "                random_state=self.config.RANDOM_SEED,\n",
    "            )\n",
    "\n",
    "            self.train_dataset = PathologyDataset(\n",
    "                data_dir=self.config.TRAIN_DATA_DIR,\n",
    "                labels_df=train_df,\n",
    "                transform=self.train_transform,\n",
    "                img_size=self.config.IMG_SIZE,\n",
    "                use_mask=self.config.USE_MASK,\n",
    "                mask_mode=self.config.MASK_MODE,\n",
    "                use_patches=self.config.USE_PATCHES,\n",
    "                patch_size=self.config.PATCH_SIZE,\n",
    "                num_patches=self.config.NUM_PATCHES,\n",
    "                use_stain_norm=self.config.USE_STAIN_NORMALIZATION,\n",
    "                label_encoder=self.label_encoder,\n",
    "            )\n",
    "\n",
    "            self.val_dataset = PathologyDataset(\n",
    "                data_dir=self.config.TRAIN_DATA_DIR,\n",
    "                labels_df=val_df,\n",
    "                transform=self.val_transform,\n",
    "                img_size=self.config.IMG_SIZE,\n",
    "                use_mask=self.config.USE_MASK,\n",
    "                mask_mode=self.config.MASK_MODE,\n",
    "                use_patches=self.config.USE_PATCHES,\n",
    "                patch_size=self.config.PATCH_SIZE,\n",
    "                num_patches=self.config.NUM_PATCHES,\n",
    "                use_stain_norm=self.config.USE_STAIN_NORMALIZATION,\n",
    "                label_encoder=self.label_encoder,\n",
    "            )\n",
    "\n",
    "            # Calculate class weights for balanced sampling\n",
    "            class_counts = train_df[\"label\"].value_counts()\n",
    "            weights = 1.0 / class_counts[train_df[\"label\"].values].values\n",
    "            self.sample_weights = torch.DoubleTensor(weights)\n",
    "\n",
    "        if stage == \"test\" or stage == \"predict\" or stage is None:\n",
    "            self.test_dataset = PathologyDataset(\n",
    "                data_dir=self.config.TEST_DATA_DIR,\n",
    "                transform=self.val_transform,\n",
    "                img_size=self.config.IMG_SIZE,\n",
    "                use_mask=self.config.USE_MASK,\n",
    "                mask_mode=self.config.MASK_MODE,\n",
    "                use_patches=self.config.USE_PATCHES,\n",
    "                patch_size=self.config.PATCH_SIZE,\n",
    "                num_patches=self.config.NUM_PATCHES,\n",
    "                use_stain_norm=self.config.USE_STAIN_NORMALIZATION,\n",
    "                is_test=True,\n",
    "                label_encoder=self.label_encoder,\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        sampler = WeightedRandomSampler(\n",
    "            self.sample_weights, len(self.sample_weights), replacement=True\n",
    "        )\n",
    "\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            sampler=sampler,\n",
    "            num_workers=self.config.NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=self.config.NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=self.config.NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self) -> DataLoader:\n",
    "        return self.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Model with Multi-Instance Learning (MIL) for patches\n",
    "# ============================================================================\n",
    "class AttentionMIL(nn.Module):\n",
    "    \"\"\"Attention-based Multiple Instance Learning pooling.\"\"\"\n",
    "\n",
    "    def __init__(self, feature_dim: int, hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(feature_dim, hidden_dim), nn.Tanh(), nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch, num_instances, features]\n",
    "        Returns:\n",
    "            pooled: [batch, features]\n",
    "            attention_weights: [batch, num_instances]\n",
    "        \"\"\"\n",
    "        # Compute attention scores\n",
    "        attn_scores = self.attention(x)  # [batch, num_instances, 1]\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)  # [batch, num_instances, 1]\n",
    "\n",
    "        # Weighted sum\n",
    "        pooled = torch.sum(x * attn_weights, dim=1)  # [batch, features]\n",
    "\n",
    "        return pooled, attn_weights.squeeze(-1)\n",
    "\n",
    "\n",
    "class PathologyClassifier(LightningModule):\n",
    "    \"\"\"Classifier optimized for histopathology with optional MIL and 4-channel input.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = Config.NUM_CLASSES,\n",
    "        model_name: str = Config.MODEL_NAME,\n",
    "        pretrained: bool = Config.PRETRAINED,\n",
    "        learning_rate: float = Config.LEARNING_RATE,\n",
    "        weight_decay: float = Config.WEIGHT_DECAY,\n",
    "        class_names: List[str] = Config.CLASSES,\n",
    "        use_patches: bool = Config.USE_PATCHES,\n",
    "        num_patches: int = Config.NUM_PATCHES,\n",
    "        in_channels: int = Config.IN_CHANNELS,  # 3 for RGB, 4 for RGB+Mask\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.class_names = class_names\n",
    "        self.use_patches = use_patches\n",
    "        self.num_patches = num_patches\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        # Create backbone\n",
    "        self.backbone, self.feature_dim = self._create_backbone(\n",
    "            model_name, pretrained, in_channels\n",
    "        )\n",
    "\n",
    "        # MIL attention pooling (for patch-based)\n",
    "        if use_patches:\n",
    "            self.mil_attention = AttentionMIL(self.feature_dim)\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.feature_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "        # Loss function\n",
    "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "        # Metrics storage\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def _modify_first_conv(\n",
    "        self, conv: nn.Conv2d, in_channels: int, pretrained: bool\n",
    "    ) -> nn.Conv2d:\n",
    "        \"\"\"Modify the first conv layer to accept different number of input channels.\"\"\"\n",
    "        if in_channels == 3:\n",
    "            return conv\n",
    "\n",
    "        # Create new conv layer with desired input channels\n",
    "        new_conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=conv.out_channels,\n",
    "            kernel_size=conv.kernel_size,\n",
    "            stride=conv.stride,\n",
    "            padding=conv.padding,\n",
    "            bias=conv.bias is not None,\n",
    "        )\n",
    "\n",
    "        if pretrained:\n",
    "            # Initialize weights: copy RGB weights and initialize new channels\n",
    "            with torch.no_grad():\n",
    "                # Copy weights for first 3 channels (RGB)\n",
    "                new_conv.weight[:, :3, :, :] = conv.weight.clone()\n",
    "\n",
    "                # Initialize additional channels (e.g., mask channel)\n",
    "                # Option 1: Initialize with mean of RGB weights\n",
    "                if in_channels > 3:\n",
    "                    mean_weight = conv.weight.mean(dim=1, keepdim=True)\n",
    "                    for i in range(3, in_channels):\n",
    "                        new_conv.weight[:, i : i + 1, :, :] = mean_weight.clone()\n",
    "\n",
    "                # Copy bias if exists\n",
    "                if conv.bias is not None:\n",
    "                    new_conv.bias = nn.Parameter(conv.bias.clone())\n",
    "\n",
    "        return new_conv\n",
    "\n",
    "    def _create_backbone(\n",
    "        self, model_name: str, pretrained: bool, in_channels: int\n",
    "    ) -> Tuple[nn.Module, int]:\n",
    "        \"\"\"Create backbone model with support for custom input channels.\"\"\"\n",
    "\n",
    "        if model_name == \"resnet50\":\n",
    "            weights = models.ResNet50_Weights.IMAGENET1K_V2 if pretrained else None\n",
    "            model = models.resnet50(weights=weights)\n",
    "            feature_dim = 2048\n",
    "\n",
    "            # Modify first conv if needed\n",
    "            if in_channels != 3:\n",
    "                model.conv1 = self._modify_first_conv(\n",
    "                    model.conv1, in_channels, pretrained\n",
    "                )\n",
    "\n",
    "            backbone = nn.Sequential(*list(model.children())[:-1], nn.Flatten())\n",
    "\n",
    "        elif model_name == \"resnet101\":\n",
    "            weights = models.ResNet101_Weights.IMAGENET1K_V2 if pretrained else None\n",
    "            model = models.resnet101(weights=weights)\n",
    "            feature_dim = 2048\n",
    "\n",
    "            if in_channels != 3:\n",
    "                model.conv1 = self._modify_first_conv(\n",
    "                    model.conv1, in_channels, pretrained\n",
    "                )\n",
    "\n",
    "            backbone = nn.Sequential(*list(model.children())[:-1], nn.Flatten())\n",
    "\n",
    "        elif model_name == \"efficientnet_b3\":\n",
    "            weights = (\n",
    "                models.EfficientNet_B3_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "            )\n",
    "            model = models.efficientnet_b3(weights=weights)\n",
    "            feature_dim = 1536\n",
    "\n",
    "            # EfficientNet first conv is in features[0][0]\n",
    "            if in_channels != 3:\n",
    "                model.features[0][0] = self._modify_first_conv(\n",
    "                    model.features[0][0], in_channels, pretrained\n",
    "                )\n",
    "\n",
    "            backbone = nn.Sequential(\n",
    "                model.features, nn.AdaptiveAvgPool2d(1), nn.Flatten()\n",
    "            )\n",
    "\n",
    "        elif model_name == \"efficientnet_b4\":\n",
    "            weights = (\n",
    "                models.EfficientNet_B4_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "            )\n",
    "            model = models.efficientnet_b4(weights=weights)\n",
    "            feature_dim = 1792\n",
    "\n",
    "            if in_channels != 3:\n",
    "                model.features[0][0] = self._modify_first_conv(\n",
    "                    model.features[0][0], in_channels, pretrained\n",
    "                )\n",
    "\n",
    "            backbone = nn.Sequential(\n",
    "                model.features, nn.AdaptiveAvgPool2d(1), nn.Flatten()\n",
    "            )\n",
    "\n",
    "        elif model_name == \"convnext_small\":\n",
    "            weights = (\n",
    "                models.ConvNeXt_Small_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "            )\n",
    "            model = models.convnext_small(weights=weights)\n",
    "            feature_dim = 768\n",
    "\n",
    "            # ConvNeXt first conv is in features[0][0]\n",
    "            if in_channels != 3:\n",
    "                model.features[0][0] = self._modify_first_conv(\n",
    "                    model.features[0][0], in_channels, pretrained\n",
    "                )\n",
    "\n",
    "            backbone = nn.Sequential(\n",
    "                model.features, nn.AdaptiveAvgPool2d(1), nn.Flatten()\n",
    "            )\n",
    "\n",
    "        elif model_name == \"densenet121\":\n",
    "            weights = models.DenseNet121_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "            model = models.densenet121(weights=weights)\n",
    "            feature_dim = 1024\n",
    "\n",
    "            # DenseNet first conv is in features.conv0\n",
    "            if in_channels != 3:\n",
    "                model.features.conv0 = self._modify_first_conv(\n",
    "                    model.features.conv0, in_channels, pretrained\n",
    "                )\n",
    "\n",
    "            backbone = nn.Sequential(\n",
    "                model.features,\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Flatten(),\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "        return backbone, feature_dim\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.use_patches:\n",
    "            # x shape: [batch, num_patches, C, H, W]\n",
    "            batch_size, num_patches, C, H, W = x.shape\n",
    "\n",
    "            # Flatten batch and patches\n",
    "            x = x.view(batch_size * num_patches, C, H, W)\n",
    "\n",
    "            # Extract features\n",
    "            features = self.backbone(x)  # [batch*num_patches, feature_dim]\n",
    "\n",
    "            # Reshape back\n",
    "            features = features.view(\n",
    "                batch_size, num_patches, -1\n",
    "            )  # [batch, num_patches, feature_dim]\n",
    "\n",
    "            # MIL attention pooling\n",
    "            pooled, _ = self.mil_attention(features)  # [batch, feature_dim]\n",
    "\n",
    "            # Classify\n",
    "            logits = self.classifier(pooled)\n",
    "        else:\n",
    "            # x shape: [batch, C, H, W]\n",
    "            features = self.backbone(x)\n",
    "            logits = self.classifier(features)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> torch.Tensor:\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = self.criterion(logits, labels)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> dict:\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = self.criterion(logits, labels)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        self.validation_step_outputs.append({\"preds\": preds, \"labels\": labels})\n",
    "\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        all_preds = torch.cat([x[\"preds\"] for x in self.validation_step_outputs])\n",
    "        all_labels = torch.cat([x[\"labels\"] for x in self.validation_step_outputs])\n",
    "\n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            mask = all_labels == i\n",
    "            if mask.sum() > 0:\n",
    "                class_acc = (all_preds[mask] == all_labels[mask]).float().mean()\n",
    "                self.log(f\"val_acc_{class_name}\", class_acc, on_epoch=True)\n",
    "\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def predict_step(\n",
    "        self, batch: Tuple[torch.Tensor, str], batch_idx: int\n",
    "    ) -> Tuple[torch.Tensor, List[str]]:\n",
    "        images, sample_indices = batch\n",
    "        logits = self(images)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        return preds, sample_indices\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay\n",
    "        )\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=10, T_mult=2, eta_min=1e-7\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"epoch\"},\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Training and Inference\n",
    "# ============================================================================\n",
    "def train_model(\n",
    "    config: Config = Config(),\n",
    ") -> Tuple[PathologyClassifier, PathologyDataModule, Trainer]:\n",
    "    \"\"\"Train the pathology classifier.\"\"\"\n",
    "\n",
    "    pl.seed_everything(config.RANDOM_SEED)\n",
    "\n",
    "    data_module = PathologyDataModule(config)\n",
    "\n",
    "    model = PathologyClassifier(\n",
    "        num_classes=config.NUM_CLASSES,\n",
    "        model_name=config.MODEL_NAME,\n",
    "        pretrained=config.PRETRAINED,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "        weight_decay=config.WEIGHT_DECAY,\n",
    "        class_names=config.CLASSES,\n",
    "        use_patches=config.USE_PATCHES,\n",
    "        num_patches=config.NUM_PATCHES,\n",
    "        in_channels=config.IN_CHANNELS,\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"checkpoints\",\n",
    "        filename=\"pathology-{epoch:02d}-{val_acc:.4f}\",\n",
    "        monitor=\"val_acc\",\n",
    "        mode=\"max\",\n",
    "        save_top_k=3,\n",
    "        save_last=True,\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"val_acc\", patience=15, mode=\"max\")\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "    logger = TensorBoardLogger(\"logs\", name=\"pathology\")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=config.MAX_EPOCHS,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        precision=\"16-mixed\",\n",
    "        callbacks=[checkpoint_callback, early_stopping, lr_monitor],\n",
    "        logger=logger,\n",
    "        gradient_clip_val=1.0,\n",
    "        accumulate_grad_batches=16,\n",
    "        deterministic=True,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "    return model, data_module, trainer\n",
    "\n",
    "\n",
    "def predict_and_save(\n",
    "    model: PathologyClassifier,\n",
    "    data_module: PathologyDataModule,\n",
    "    trainer: Trainer,\n",
    "    output_path: str = Config.OUTPUT_PATH,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Run inference and save predictions.\"\"\"\n",
    "\n",
    "    data_module.setup(stage=\"predict\")\n",
    "    predictions = trainer.predict(model, datamodule=data_module)\n",
    "\n",
    "    all_preds = []\n",
    "    all_indices = []\n",
    "\n",
    "    for preds, indices in predictions:\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_indices.extend(indices)\n",
    "\n",
    "    label_encoder = data_module.label_encoder\n",
    "    predicted_labels = label_encoder.inverse_transform(all_preds)\n",
    "\n",
    "    results_df = pd.DataFrame({\"sample_index\": all_indices, \"label\": predicted_labels})\n",
    "\n",
    "    results_df = results_df.sort_values(\"sample_index\").reset_index(drop=True)\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Predictions saved to: {output_path}\")\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Pathology-Optimized Molecular Subtype Classification\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model: {config.MODEL_NAME}\")\n",
    "print(f\"Image Size: {config.IMG_SIZE}\")\n",
    "print(\n",
    "    f\"Input Channels: {config.IN_CHANNELS} ({'RGB + Mask' if config.IN_CHANNELS == 4 else 'RGB'})\"\n",
    ")\n",
    "print(f\"Mask Mode: {config.MASK_MODE}\")\n",
    "print(f\"Use Patches: {config.USE_PATCHES}\")\n",
    "if config.USE_PATCHES:\n",
    "    print(f\"  - Patch Size: {config.PATCH_SIZE}\")\n",
    "    print(f\"  - Num Patches: {config.NUM_PATCHES}\")\n",
    "print(f\"Stain Normalization: {config.USE_STAIN_NORMALIZATION}\")\n",
    "print(f\"Batch Size: {config.BATCH_SIZE}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n[1/2] Training model...\")\n",
    "model, data_module, trainer = train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[2/2] Running inference on test set...\")\n",
    "results_df = predict_and_save(model, data_module, trainer, config.OUTPUT_PATH)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Prediction Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(results_df[\"label\"].value_counts())\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
